+++ headers/rtc_4.5.0/include/AgoraMediaBase.h	2024-09-27 19:00:43
@@ -63,8 +63,8 @@
 
 
 /**
-* Video source types definition.
-**/
+ * Video source types definition.
+ **/
 enum VIDEO_SOURCE_TYPE {
   /** Video captured by the camera.
    */
@@ -122,10 +122,38 @@
 };
 
 /**
+* Audio source types definition.
+**/
+enum AUDIO_SOURCE_TYPE {
+  /** Audio captured by the mic.
+   */
+  AUDIO_SOURCE_MICROPHONE = 0,
+  /** Not define.
+   */
+  AUDIO_SOURCE_CUSTOM = 1,
+  /** Audio for media player sharing.
+   */
+  AUDIO_SOURCE_MEDIA_PLAYER = 2,
+  /** Audio for screen audio.
+   */
+  AUDIO_SOURCE_LOOPBACK_RECORDING = 3,
+  /** Audio captured by mixed source.
+   */
+  AUDIO_SOURCE_MIXED_STREAM = 4,
+  /** Remote audio received from network.
+   */
+  AUDIO_SOURCE_REMOTE_USER = 5,
+  /** Remote audio received from network by channel.
+   */
+  AUDIO_SOURCE_REMOTE_CHANNEL = 6,
+
+  AUDIO_SOURCE_UNKNOWN = 100
+};
+
+/**
  * Audio routes.
  */
-enum AudioRoute
-{
+enum AudioRoute {
   /**
    * -1: The default audio route.
    */
@@ -191,10 +219,7 @@
   size_t channels;
   size_t frames_per_buffer;
 
-  AudioParameters()
-      : sample_rate(0),
-        channels(0),
-        frames_per_buffer(0) {}
+  AudioParameters() : sample_rate(0), channels(0), frames_per_buffer(0) {}
 };
 
 /**
@@ -207,7 +232,8 @@
   RAW_AUDIO_FRAME_OP_MODE_READ_ONLY = 0,
 
   /** 2: Read and write mode: Users read the data from `AudioFrame`, modify it, and then play it. 
-   * For example, when users have their own audio-effect processing module and perform some voice pre-processing, such as a voice change.
+   * For example, when users have their own audio-effect processing module and perform some voice
+   * pre-processing, such as a voice change.
    */
   RAW_AUDIO_FRAME_OP_MODE_READ_WRITE = 2,
 };
@@ -215,7 +241,7 @@
 }  // namespace rtc
 
 namespace media {
-  /**
+/**
  * The type of media device.
  */
 enum MEDIA_SOURCE_TYPE {
@@ -290,23 +316,23 @@
 };
 
 enum CONTENT_INSPECT_TYPE {
-/**
+  /**
  * (Default) content inspect type invalid
  */
-CONTENT_INSPECT_INVALID = 0,
-/**
+  CONTENT_INSPECT_INVALID = 0,
+  /**
  * @deprecated
  * Content inspect type moderation
  */
-CONTENT_INSPECT_MODERATION __deprecated = 1,
-/**
+  CONTENT_INSPECT_MODERATION __deprecated = 1,
+  /**
  * Content inspect type supervise
  */
-CONTENT_INSPECT_SUPERVISION = 2,
-/**
+  CONTENT_INSPECT_SUPERVISION = 2,
+  /**
  * Content inspect type image moderation
  */
-CONTENT_INSPECT_IMAGE_MODERATION = 3
+  CONTENT_INSPECT_IMAGE_MODERATION = 3
 };
 
 struct ContentInspectModule {
@@ -338,15 +364,14 @@
   /**The content inspect module count.
    */
   int moduleCount;
-   ContentInspectConfig& operator=(const ContentInspectConfig& rth)
-	{
+  ContentInspectConfig& operator=(const ContentInspectConfig& rth) {
         extraInfo = rth.extraInfo;
         serverConfig = rth.serverConfig;
         moduleCount = rth.moduleCount;
 		memcpy(&modules, &rth.modules,  MAX_CONTENT_INSPECT_MODULE_COUNT * sizeof(ContentInspectModule));
 		return *this;
 	}
-  ContentInspectConfig() :extraInfo(NULL), serverConfig(NULL), moduleCount(0){}
+  ContentInspectConfig() : extraInfo(NULL), serverConfig(NULL), moduleCount(0) {}
 };
 
 namespace base {
@@ -368,9 +393,7 @@
   uint32_t timestamp;
   // Audio level indication.
   uint8_t audioLevelIndication;
-  PacketOptions()
-      : timestamp(0),
-        audioLevelIndication(127) {}
+  PacketOptions() : timestamp(0), audioLevelIndication(127) {}
 };
 
 /**
@@ -386,9 +409,7 @@
    * The codec of the packet.
    */
   uint8_t codec;
-  AudioEncodedFrameInfo()
-      : sendTs(0),
-        codec(0) {}
+  AudioEncodedFrameInfo() : sendTs(0), codec(0) {}
 };
 
 /**
@@ -398,13 +419,14 @@
   /**
    * The buffer size of the PCM audio frame.
    */
-  OPTIONAL_ENUM_SIZE_T {
+  OPTIONAL_ENUM_SIZE_T{
     // Stereo, 32 kHz, 60 ms (2 * 32 * 60)
     /**
      * The max number of the samples of the data.
      *
      * When the number of audio channel is two, the sample rate is 32 kHZ,
-     * the buffer length of the data is 60 ms, the number of the samples of the data is 3840 (2 x 32 x 60).
+       * the buffer length of the data is 60 ms, the number of the samples of the data is 3840 (2 x
+       * 32 x 60).
        */
       kMaxDataSizeSamples = 3840,
       /** The max number of the bytes of the data. */
@@ -553,7 +575,8 @@
    */
   VIDEO_PIXEL_I422 = 16,
   /**
-   * 17: ID3D11Texture2D, only support DXGI_FORMAT_B8G8R8A8_UNORM, DXGI_FORMAT_B8G8R8A8_TYPELESS, DXGI_FORMAT_NV12 texture format
+   * 17: ID3D11Texture2D, only support DXGI_FORMAT_B8G8R8A8_UNORM, DXGI_FORMAT_B8G8R8A8_TYPELESS,
+   * DXGI_FORMAT_NV12 texture format
    */
   VIDEO_TEXTURE_ID3D11TEXTURE2D = 17,
   /**
@@ -612,7 +635,7 @@
     enum META_INFO_KEY {
       KEY_FACE_CAPTURE = 0,
     };
-    virtual ~IVideoFrameMetaInfo() {};
+  virtual ~IVideoFrameMetaInfo(){};
   virtual const char* getMetaInfoStr(META_INFO_KEY key) const = 0;
 };
 
@@ -869,6 +892,7 @@
    * The pixel format: #VIDEO_PIXEL_FORMAT
    */
   VIDEO_PIXEL_FORMAT format;
+
   /**
    * The video buffer.
    */
@@ -903,13 +927,13 @@
    */
   int cropBottom;
   /**
-   * [Raw data related parameter] The clockwise rotation information of the video frame. You can set the
-   * rotation angle as 0, 90, 180, or 270. The default value is 0.
+   * [Raw data related parameter] The clockwise rotation information of the video frame. You can set
+   * the rotation angle as 0, 90, 180, or 270. The default value is 0.
    */
   int rotation;
   /**
-   * The timestamp (ms) of the incoming video frame. An incorrect timestamp results in a frame loss or
-   * unsynchronized audio and video.
+   * The timestamp (ms) of the incoming video frame. An incorrect timestamp results in a frame loss
+   * or unsynchronized audio and video.
    *
    * Please refer to getAgoraCurrentMonotonicTimeInMs or getCurrentMonotonicTimeInMs
    * to determine how to fill this filed.
@@ -917,16 +941,18 @@
   long long timestamp;
   /**
    * [Texture-related parameter]
-   * When using the OpenGL interface (javax.microedition.khronos.egl.*) defined by Khronos, set EGLContext to this field.
-   * When using the OpenGL interface (android.opengl.*) defined by Android, set EGLContext to this field.
+   * When using the OpenGL interface (javax.microedition.khronos.egl.*) defined by Khronos, set
+   * EGLContext to this field. When using the OpenGL interface (android.opengl.*) defined by
+   * Android, set EGLContext to this field.
    */
-  void *eglContext;
+  void* eglContext;
   /**
    * [Texture related parameter] Texture ID used by the video frame.
    */
   EGL_CONTEXT_TYPE eglType;
   /**
-   * [Texture related parameter] Incoming 4 &times; 4 transformational matrix. The typical value is a unit matrix.
+   * [Texture related parameter] Incoming 4 &times; 4 transformational matrix. The typical value is
+   * a unit matrix.
    */
   int textureId;
   /**
@@ -1060,8 +1086,8 @@
    */
   int rotation;
   /**
-   * The timestamp to render the video stream. Use this parameter for audio-video synchronization when
-   * rendering the video.
+   * The timestamp to render the video stream. Use this parameter for audio-video synchronization
+   * when rendering the video.
    *
    * @note This parameter is for rendering the video, not capturing the video.
    */
@@ -1089,7 +1115,8 @@
    */
   int textureId;
   /**
-   * [Texture related parameter] The pointer of ID3D11Texture2D used by the video frame,for Windows only.
+   * [Texture related parameter] The pointer of ID3D11Texture2D used by the video frame,for Windows
+   * only.
    */
   void* d3d11Texture2d;
   /**
@@ -1117,7 +1144,8 @@
    */
   void* pixelBuffer;
   /**
-   *  The pointer to IVideoFrameMetaInfo, which is the interface to get metainfo contents from VideoFrame. 
+   *  The pointer to IVideoFrameMetaInfo, which is the interface to get metainfo contents from
+   * VideoFrame.
    */
   IVideoFrameMetaInfo* metaInfo;
 
@@ -1141,7 +1169,8 @@
    * Occurs each time the player receives a video frame.
    *
    * After registering the video frame observer,
-   * the callback occurs each time the player receives a video frame to report the detailed information of the video frame.
+   * the callback occurs each time the player receives a video frame to report the detailed
+   * information of the video frame.
    * @param frame The detailed information of the video frame. See {@link VideoFrame}.
    */
   virtual void onFrame(const VideoFrame* frame) = 0;
@@ -1179,7 +1208,31 @@
 
 }  // namespace base
 
-/**
+/** Definition of SnapshotConfig.
+ */
+struct SnapshotConfig {
+  /** 
+   * The local path (including filename extensions) of the snapshot. For example:
+   * - Windows: `C:\Users\<user_name>\AppData\Local\Agora\<process_name>\example.jpg`
+   * - iOS: `/App Sandbox/Library/Caches/example.jpg`
+   * - macOS: `ï½ž/Library/Logs/example.jpg`
+   * - Android: `/storage/emulated/0/Android/data/<package name>/files/example.jpg`
+   */
+  const char* filePath;
+
+  /** 
+   * The position of the video observation. See VIDEO_MODULE_POSITION.
+   * 
+   * Allowed values vary depending on the `uid` parameter passed in `takeSnapshot` or `takeSnapshotEx`:
+   * - uid = 0: Position 2, 4 and 8 are allowed.
+   * - uid != 0: Only position 2 is allowed.
+   * 
+   */
+  media::base::VIDEO_MODULE_POSITION position;
+  SnapshotConfig() :filePath(NULL), position(media::base::POSITION_PRE_ENCODER) {}
+};
+
+/**
  * The audio frame observer.
  */
 class IAudioPcmFrameSink {
@@ -1263,8 +1316,8 @@
     /**
      * The pts timestamp of this audio frame.
      *
-     * This timestamp is used to indicate the origin pts time of the frame, and sync with video frame by
-     * the pts time stamp
+     * This timestamp is used to indicate the origin pts time of the frame, and sync with video
+     * frame by the pts time stamp
      */
     int64_t presentationMs;
     /**
@@ -1276,7 +1329,8 @@
      */
     uint32_t rtpTimestamp;
 
-    AudioFrame() : type(FRAME_TYPE_PCM16),
+    AudioFrame()
+        : type(FRAME_TYPE_PCM16),
           samplesPerChannel(0),
           bytesPerSample(rtc::TWO_BYTES_PER_SAMPLE),
           channels(0),
@@ -1335,8 +1389,17 @@
      */
     int samples_per_call;
 
-    AudioParams() : sample_rate(0), channels(0), mode(rtc::RAW_AUDIO_FRAME_OP_MODE_READ_ONLY), samples_per_call(0) {}
-    AudioParams(int samplerate, int channel, rtc::RAW_AUDIO_FRAME_OP_MODE_TYPE type, int samplesPerCall) : sample_rate(samplerate), channels(channel), mode(type), samples_per_call(samplesPerCall) {}
+    AudioParams()
+        : sample_rate(0),
+          channels(0),
+          mode(rtc::RAW_AUDIO_FRAME_OP_MODE_READ_ONLY),
+          samples_per_call(0) {}
+    AudioParams(int samplerate, int channel, rtc::RAW_AUDIO_FRAME_OP_MODE_TYPE type,
+                int samplesPerCall)
+        : sample_rate(samplerate),
+          channels(channel),
+          mode(type),
+          samples_per_call(samplesPerCall) {}
   };
 
  public:
@@ -1386,10 +1449,11 @@
    * - true: The before-mixing playback audio frame is valid and is encoded and sent.
    * - false: The before-mixing playback audio frame is invalid and is not encoded or sent.
    */
-  virtual bool onPlaybackAudioFrameBeforeMixing(const char* channelId, base::user_id_t userId, AudioFrame& audioFrame) {
-    (void) channelId;
-    (void) userId;
-    (void) audioFrame;
+  virtual bool onPlaybackAudioFrameBeforeMixing(const char* channelId, base::user_id_t userId,
+                                                AudioFrame& audioFrame) {
+    (void)channelId;
+    (void)userId;
+    (void)audioFrame;
     return true;
   }
 
@@ -1398,12 +1462,19 @@
    * @return A bit mask that controls the frame position of the audio observer.
    * @note - Use '|' (the OR operator) to observe multiple frame positions.
    * <p>
-   * After you successfully register the audio observer, the SDK triggers this callback each time it receives a audio frame. You can determine which position to observe by setting the return value.
-   * The SDK provides 4 positions for observer. Each position corresponds to a callback function:
-   * - `AUDIO_FRAME_POSITION_PLAYBACK (1 << 0)`: The position for playback audio frame is received, which corresponds to the \ref onPlaybackFrame "onPlaybackFrame" callback.
-   * - `AUDIO_FRAME_POSITION_RECORD (1 << 1)`: The position for record audio frame is received, which corresponds to the \ref onRecordFrame "onRecordFrame" callback.
-   * - `AUDIO_FRAME_POSITION_MIXED (1 << 2)`: The position for mixed audio frame is received, which corresponds to the \ref onMixedFrame "onMixedFrame" callback.
-   * - `AUDIO_FRAME_POSITION_BEFORE_MIXING (1 << 3)`: The position for playback audio frame before mixing is received, which corresponds to the \ref onPlaybackFrameBeforeMixing "onPlaybackFrameBeforeMixing" callback.
+   * After you successfully register the audio observer, the SDK triggers this callback each time it
+   * receives a audio frame. You can determine which position to observe by setting the return
+   * value. The SDK provides 4 positions for observer. Each position corresponds to a callback
+   * function:
+   * - `AUDIO_FRAME_POSITION_PLAYBACK (1 << 0)`: The position for playback audio frame is received,
+   * which corresponds to the \ref onPlaybackFrame "onPlaybackFrame" callback.
+   * - `AUDIO_FRAME_POSITION_RECORD (1 << 1)`: The position for record audio frame is received,
+   * which corresponds to the \ref onRecordFrame "onRecordFrame" callback.
+   * - `AUDIO_FRAME_POSITION_MIXED (1 << 2)`: The position for mixed audio frame is received, which
+   * corresponds to the \ref onMixedFrame "onMixedFrame" callback.
+   * - `AUDIO_FRAME_POSITION_BEFORE_MIXING (1 << 3)`: The position for playback audio frame before
+   * mixing is received, which corresponds to the \ref onPlaybackFrameBeforeMixing
+   * "onPlaybackFrameBeforeMixing" callback.
    *  @return The bit mask that controls the audio observation positions.
    * See AUDIO_FRAME_POSITION.
    */
@@ -1475,22 +1546,22 @@
    * - true: The before-mixing playback audio frame is valid and is encoded and sent.
    * - false: The before-mixing playback audio frame is invalid and is not encoded or sent.
    */
-  virtual bool onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid, AudioFrame& audioFrame) = 0;
+  virtual bool onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid,
+                                                AudioFrame& audioFrame) = 0;
 };
 
 struct AudioSpectrumData {
   /**
    * The audio spectrum data of audio.
    */
-  const float *audioSpectrumData;
+  const float* audioSpectrumData;
   /**
    * The data length of audio spectrum data.
    */
   int dataLength;
 
   AudioSpectrumData() : audioSpectrumData(NULL), dataLength(0) {}
-  AudioSpectrumData(const float *data, int length) :
-    audioSpectrumData(data), dataLength(length) {}
+  AudioSpectrumData(const float* data, int length) : audioSpectrumData(data), dataLength(length) {}
 };
 
 struct UserAudioSpectrumInfo {
@@ -1505,14 +1576,15 @@
 
   UserAudioSpectrumInfo() : uid(0) {}
 
-  UserAudioSpectrumInfo(agora::rtc::uid_t uid, const float* data, int length) : uid(uid), spectrumData(data, length) {}
+  UserAudioSpectrumInfo(agora::rtc::uid_t uid, const float* data, int length)
+      : uid(uid), spectrumData(data, length) {}
 };
 
 /**
  * The IAudioSpectrumObserver class.
  */
 class IAudioSpectrumObserver {
-public:
+ public:
   virtual ~IAudioSpectrumObserver() {}
 
   /**
@@ -1521,7 +1593,8 @@
    * This callback reports the audio spectrum data of the local audio at the moment
    * in the channel.
    *
-   * You can set the time interval of this callback using \ref ILocalUser::enableAudioSpectrumMonitor "enableAudioSpectrumMonitor".
+   * You can set the time interval of this callback using \ref
+   * ILocalUser::enableAudioSpectrumMonitor "enableAudioSpectrumMonitor".
    *
    * @param data The audio spectrum data of local audio.
    * - true: Processed.
@@ -1534,10 +1607,12 @@
    * This callback reports the IDs and audio spectrum data of the loudest speakers at the moment
    * in the channel.
    *
-   * You can set the time interval of this callback using \ref ILocalUser::enableAudioSpectrumMonitor "enableAudioSpectrumMonitor".
+   * You can set the time interval of this callback using \ref
+   * ILocalUser::enableAudioSpectrumMonitor "enableAudioSpectrumMonitor".
    *
-   * @param spectrums The pointer to \ref agora::media::UserAudioSpectrumInfo "UserAudioSpectrumInfo", which is an array containing
-   * the user ID and audio spectrum data for each speaker.
+   * @param spectrums The pointer to \ref agora::media::UserAudioSpectrumInfo
+   * "UserAudioSpectrumInfo", which is an array containing the user ID and audio spectrum data for
+   * each speaker.
    * - This array contains the following members:
    *   - `uid`, which is the UID of each remote speaker
    *   - `spectrumData`, which reports the audio spectrum of each remote speaker.
@@ -1545,7 +1620,8 @@
    * - true: Processed.
    * - false: Not processed.
    */
-  virtual bool onRemoteAudioSpectrum(const UserAudioSpectrumInfo* spectrums, unsigned int spectrumNumber) = 0;
+  virtual bool onRemoteAudioSpectrum(const UserAudioSpectrumInfo* spectrums,
+                                     unsigned int spectrumNumber) = 0;
 };
 
 /**
@@ -1563,7 +1639,8 @@
    * - true: Accept.
    * - false: Do not accept.
    */
-  virtual bool onEncodedVideoFrameReceived(rtc::uid_t uid, const uint8_t* imageBuffer, size_t length,
+  virtual bool onEncodedVideoFrameReceived(
+      rtc::uid_t uid, const uint8_t* imageBuffer, size_t length,
       const rtc::EncodedVideoFrameInfo& videoEncodedFrameInfo) = 0;
 
   virtual ~IVideoEncodedFrameObserver() {}
@@ -1584,13 +1661,15 @@
      * 
      * In this mode, you do not modify the video frame. The video frame observer is a renderer.
      */
-    PROCESS_MODE_READ_ONLY, // Observer works as a pure renderer and will not modify the original frame.
+    PROCESS_MODE_READ_ONLY,  // Observer works as a pure renderer and will not modify the original
+                             // frame.
     /**
      * Read and write mode.
      * 
      * In this mode, you modify the video frame. The video frame observer is a video filter.
      */
-    PROCESS_MODE_READ_WRITE, // Observer works as a filter that will process the video frame and affect the following frame processing in SDK.
+    PROCESS_MODE_READ_WRITE,  // Observer works as a filter that will process the video frame and
+                              // affect the following frame processing in SDK.
   };
 
  public:
@@ -1599,16 +1678,18 @@
   /**
    * Occurs each time the SDK receives a video frame captured by the local camera.
    *
-   * After you successfully register the video frame observer, the SDK triggers this callback each time
-   * a video frame is received. In this callback, you can get the video data captured by the local
-   * camera. You can then pre-process the data according to your scenarios.
+   * After you successfully register the video frame observer, the SDK triggers this callback each
+   * time a video frame is received. In this callback, you can get the video data captured by the
+   * local camera. You can then pre-process the data according to your scenarios.
    *
    * After pre-processing, you can send the processed video data back to the SDK by setting the
    * `videoFrame` parameter in this callback.
    *
    * @note
-   * - If you get the video data in RGBA color encoding format, Agora does not support using this callback to send the processed data in RGBA color encoding format back to the SDK.
-   * - The video data that this callback gets has not been pre-processed, such as watermarking, cropping content, rotating, or image enhancement.
+   * - If you get the video data in RGBA color encoding format, Agora does not support using this
+   * callback to send the processed data in RGBA color encoding format back to the SDK.
+   * - The video data that this callback gets has not been pre-processed, such as watermarking,
+   * cropping content, rotating, or image enhancement.
    *
    * @param videoFrame A pointer to the video frame: VideoFrame
    * @param sourceType source type of video frame. See #VIDEO_SOURCE_TYPE.
@@ -1616,21 +1697,24 @@
    * - true: Do not ignore.
    * - false: Ignore, in which case this method does not sent the current video frame to the SDK.
   */
-  virtual bool onCaptureVideoFrame(agora::rtc::VIDEO_SOURCE_TYPE sourceType, VideoFrame& videoFrame) = 0;
+  virtual bool onCaptureVideoFrame(agora::rtc::VIDEO_SOURCE_TYPE sourceType,
+                                   VideoFrame& videoFrame) = 0;
 
   /**
    * Occurs each time the SDK receives a video frame before encoding.
    *
-   * After you successfully register the video frame observer, the SDK triggers this callback each time
-   * when it receives a video frame. In this callback, you can get the video data before encoding. You can then
-   * process the data according to your particular scenarios.
+   * After you successfully register the video frame observer, the SDK triggers this callback each
+   * time when it receives a video frame. In this callback, you can get the video data before
+   * encoding. You can then process the data according to your particular scenarios.
    *
    * After processing, you can send the processed video data back to the SDK by setting the
    * `videoFrame` parameter in this callback.
    *
    * @note
-   * - To get the video data captured from the second screen before encoding, you need to set (1 << 2) as a frame position through `getObservedFramePosition`.
-   * - The video data that this callback gets has been pre-processed, such as watermarking, cropping content, rotating, or image enhancement.
+   * - To get the video data captured from the second screen before encoding, you need to set (1 <<
+   * 2) as a frame position through `getObservedFramePosition`.
+   * - The video data that this callback gets has been pre-processed, such as watermarking, cropping
+   * content, rotating, or image enhancement.
    * - This callback does not support sending processed RGBA video data back to the SDK.
    *
    * @param videoFrame A pointer to the video frame: VideoFrame
@@ -1639,7 +1723,8 @@
    * - true: Do not ignore.
    * - false: Ignore, in which case this method does not sent the current video frame to the SDK.
    */
-  virtual bool onPreEncodeVideoFrame(agora::rtc::VIDEO_SOURCE_TYPE sourceType, VideoFrame& videoFrame) = 0;
+  virtual bool onPreEncodeVideoFrame(agora::rtc::VIDEO_SOURCE_TYPE sourceType,
+                                     VideoFrame& videoFrame) = 0;
 
   /**
    * Occurs each time the SDK receives a video frame decoded by the MediaPlayer.
@@ -1652,8 +1737,11 @@
    * `videoFrame` parameter in this callback.
    * 
    * @note
-   * - This callback will not be affected by the return values of \ref getVideoFrameProcessMode "getVideoFrameProcessMode", \ref getRotationApplied "getRotationApplied", \ref getMirrorApplied "getMirrorApplied", \ref getObservedFramePosition "getObservedFramePosition".
-   * - On Android, this callback is not affected by the return value of \ref getVideoFormatPreference "getVideoFormatPreference"
+   * - This callback will not be affected by the return values of \ref getVideoFrameProcessMode
+   * "getVideoFrameProcessMode", \ref getRotationApplied "getRotationApplied", \ref getMirrorApplied
+   * "getMirrorApplied", \ref getObservedFramePosition "getObservedFramePosition".
+   * - On Android, this callback is not affected by the return value of \ref
+   * getVideoFormatPreference "getVideoFormatPreference"
    *
    * @param videoFrame A pointer to the video frame: VideoFrame
    * @param mediaPlayerId ID of the mediaPlayer.
@@ -1666,12 +1754,12 @@
   /**
    * Occurs each time the SDK receives a video frame sent by the remote user.
    *
-   * After you successfully register the video frame observer, the SDK triggers this callback each time a
-   * video frame is received. In this callback, you can get the video data sent by the remote user. You
-   * can then post-process the data according to your scenarios.
+   * After you successfully register the video frame observer, the SDK triggers this callback each
+   * time a video frame is received. In this callback, you can get the video data sent by the remote
+   * user. You can then post-process the data according to your scenarios.
    *
-   * After post-processing, you can send the processed data back to the SDK by setting the `videoFrame`
-   * parameter in this callback.
+   * After post-processing, you can send the processed data back to the SDK by setting the
+   * `videoFrame` parameter in this callback.
    *
    * @note This callback does not support sending processed RGBA video data back to the SDK.
    *
@@ -1682,44 +1770,47 @@
    * - true: Do not ignore.
    * - false: Ignore, in which case this method does not sent the current video frame to the SDK.
    */
-  virtual bool onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame) = 0;
+  virtual bool onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid,
+                                  VideoFrame& videoFrame) = 0;
 
   virtual bool onTranscodedVideoFrame(VideoFrame& videoFrame) = 0;
 
   /**
-   * Occurs each time the SDK receives a video frame and prompts you to set the process mode of the video frame.
+   * Occurs each time the SDK receives a video frame and prompts you to set the process mode of the
+   * video frame.
    * 
-   * After you successfully register the video frame observer, the SDK triggers this callback each time it receives 
-   * a video frame. You need to set your preferred process mode in the return value of this callback.
+   * After you successfully register the video frame observer, the SDK triggers this callback each
+   * time it receives a video frame. You need to set your preferred process mode in the return value
+   * of this callback.
    * @return VIDEO_FRAME_PROCESS_MODE.
    */
-  virtual VIDEO_FRAME_PROCESS_MODE getVideoFrameProcessMode() {
-    return PROCESS_MODE_READ_ONLY;
-  }
+  virtual VIDEO_FRAME_PROCESS_MODE getVideoFrameProcessMode() { return PROCESS_MODE_READ_ONLY; }
 
   /**
    * Sets the format of the raw video data output by the SDK.
    *
-   * If you want to get raw video data in a color encoding format other than YUV 420, register this callback when 
-   * calling `registerVideoFrameObserver`. After you successfully register the video frame observer, the SDK triggers 
-   * this callback each time it receives a video frame. You need to set your preferred video data in the return value 
-   * of this callback.
+   * If you want to get raw video data in a color encoding format other than YUV 420, register this
+   * callback when calling `registerVideoFrameObserver`. After you successfully register the video
+   * frame observer, the SDK triggers this callback each time it receives a video frame. You need to
+   * set your preferred video data in the return value of this callback.
    * 
-   * @note If you want the video captured by the sender to be the original format, set the original video data format 
-   * to VIDEO_PIXEL_DEFAULT in the return value. On different platforms, the original video pixel format is also 
-   * different, for the actual video pixel format, see `VideoFrame`.
+   * @note If you want the video captured by the sender to be the original format, set the original
+   * video data format to VIDEO_PIXEL_DEFAULT in the return value. On different platforms, the
+   * original video pixel format is also different, for the actual video pixel format, see
+   * `VideoFrame`.
    * 
    * @return Sets the video format. See VIDEO_PIXEL_FORMAT.
    */
   virtual base::VIDEO_PIXEL_FORMAT getVideoFormatPreference() { return base::VIDEO_PIXEL_DEFAULT; }
 
   /**
-   * Occurs each time the SDK receives a video frame, and prompts you whether to rotate the captured video.
+   * Occurs each time the SDK receives a video frame, and prompts you whether to rotate the captured
+   * video.
    * 
-   * If you want to rotate the captured video according to the rotation member in the `VideoFrame` class, register this 
-   * callback by calling `registerVideoFrameObserver`. After you successfully register the video frame observer, the 
-   * SDK triggers this callback each time it receives a video frame. You need to set whether to rotate the video frame 
-   * in the return value of this callback.
+   * If you want to rotate the captured video according to the rotation member in the `VideoFrame`
+   * class, register this callback by calling `registerVideoFrameObserver`. After you successfully
+   * register the video frame observer, the SDK triggers this callback each time it receives a video
+   * frame. You need to set whether to rotate the video frame in the return value of this callback.
    *
    * @note This function only supports video data in RGBA or YUV420.
    *
@@ -1730,12 +1821,14 @@
   virtual bool getRotationApplied() { return false; }
 
   /**
-   * Occurs each time the SDK receives a video frame and prompts you whether or not to mirror the captured video.
+   * Occurs each time the SDK receives a video frame and prompts you whether or not to mirror the
+   * captured video.
    * 
-   * If the video data you want to obtain is a mirror image of the original video, you need to register this callback 
-   * when calling `registerVideoFrameObserver`. After you successfully register the video frame observer, the SDK 
-   * triggers this callback each time it receives a video frame. You need to set whether or not to mirror the video 
-   * frame in the return value of this callback.
+   * If the video data you want to obtain is a mirror image of the original video, you need to
+   * register this callback when calling `registerVideoFrameObserver`. After you successfully
+   * register the video frame observer, the SDK triggers this callback each time it receives a video
+   * frame. You need to set whether or not to mirror the video frame in the return value of this
+   * callback.
    *
    * @note This function only supports video data in RGBA and YUV420 formats.
    *
@@ -1748,19 +1841,24 @@
   /**
    * Sets the frame position for the video observer.
    *
-   * After you successfully register the video observer, the SDK triggers this callback each time it receives
-   * a video frame. You can determine which position to observe by setting the return value. The SDK provides
-   * 3 positions for observer. Each position corresponds to a callback function:
+   * After you successfully register the video observer, the SDK triggers this callback each time it
+   * receives a video frame. You can determine which position to observe by setting the return
+   * value. The SDK provides 3 positions for observer. Each position corresponds to a callback
+   * function:
    *
-   * POSITION_POST_CAPTURER(1 << 0): The position after capturing the video data, which corresponds to the onCaptureVideoFrame callback.
-   * POSITION_PRE_RENDERER(1 << 1): The position before receiving the remote video data, which corresponds to the onRenderVideoFrame callback.
-   * POSITION_PRE_ENCODER(1 << 2): The position before encoding the video data, which corresponds to the onPreEncodeVideoFrame callback.
+   * POSITION_POST_CAPTURER(1 << 0): The position after capturing the video data, which corresponds
+   * to the onCaptureVideoFrame callback. POSITION_PRE_RENDERER(1 << 1): The position before
+   * receiving the remote video data, which corresponds to the onRenderVideoFrame callback.
+   * POSITION_PRE_ENCODER(1 << 2): The position before encoding the video data, which corresponds to
+   * the onPreEncodeVideoFrame callback.
    *
    * To observe multiple frame positions, use '|' (the OR operator).
-   * This callback observes POSITION_POST_CAPTURER(1 << 0) and POSITION_PRE_RENDERER(1 << 1) by default.
-   * To conserve the system consumption, you can reduce the number of frame positions that you want to observe.
+   * This callback observes POSITION_POST_CAPTURER(1 << 0) and POSITION_PRE_RENDERER(1 << 1) by
+   * default. To conserve the system consumption, you can reduce the number of frame positions that
+   * you want to observe.
    *
-   * @return A bit mask that controls the frame position of the video observer: VIDEO_OBSERVER_POSITION.
+   * @return A bit mask that controls the frame position of the video observer:
+   * VIDEO_OBSERVER_POSITION.
    */
   virtual uint32_t getObservedFramePosition() {
     return base::POSITION_POST_CAPTURER | base::POSITION_PRE_RENDERER;
@@ -1854,7 +1952,8 @@
    */
   RECORDER_REASON_WRITE_FAILED = 1,
   /**
-   * 2: The SDK does not detect audio and video streams to be recorded, or audio and video streams are interrupted for more than five seconds during recording.
+   * 2: The SDK does not detect audio and video streams to be recorded, or audio and video streams
+   * are interrupted for more than five seconds during recording.
    */
   RECORDER_REASON_NO_STREAM = 2,
   /**
@@ -1882,7 +1981,8 @@
    */
   const char* storagePath;
   /**
-   * The format of the recording file. See \ref agora::rtc::MediaRecorderContainerFormat "MediaRecorderContainerFormat".
+   * The format of the recording file. See \ref agora::rtc::MediaRecorderContainerFormat
+   * "MediaRecorderContainerFormat".
    */
   MediaRecorderContainerFormat containerFormat;
   /**
@@ -1900,13 +2000,60 @@
    * callback to report the updated recording information.
    */
   int recorderInfoUpdateInterval;
+  /**
+   * The video width
+   */
+  int width;
+  /**
+   * The video height
+   */
+  int height;
+  /**
+   * The video fps
+   */
+  int fps;
+  /**
+   * The audio sample rate
+   */
+  int sample_rate;
+  /**
+   * The audio channel nums
+   */
+  int channel_num;
+  /**
+   * The video source just for out channel recoder
+   */
+  agora::rtc::VIDEO_SOURCE_TYPE videoSourceType;
 
-  MediaRecorderConfiguration() : storagePath(NULL), containerFormat(FORMAT_MP4), streamType(STREAM_TYPE_BOTH), maxDurationMs(120000), recorderInfoUpdateInterval(0) {}
-  MediaRecorderConfiguration(const char* path, MediaRecorderContainerFormat format, MediaRecorderStreamType type, int duration, int interval) : storagePath(path), containerFormat(format), streamType(type), maxDurationMs(duration), recorderInfoUpdateInterval(interval) {}
+  MediaRecorderConfiguration()
+      : storagePath(NULL),
+        containerFormat(FORMAT_MP4),
+        streamType(STREAM_TYPE_BOTH),
+        maxDurationMs(120000),
+        recorderInfoUpdateInterval(0),
+        width(1280),
+        height(720),
+        fps(30),
+        sample_rate(48000),
+        channel_num(1),
+        videoSourceType(rtc::VIDEO_SOURCE_CAMERA_PRIMARY) {}
+  MediaRecorderConfiguration(const char* path, MediaRecorderContainerFormat format,
+                             MediaRecorderStreamType type, int duration, int interval)
+      : storagePath(path),
+        containerFormat(format),
+        streamType(type),
+        maxDurationMs(duration),
+        recorderInfoUpdateInterval(interval),
+        width(1280),
+        height(720),
+        fps(30),
+        sample_rate(48000),
+        channel_num(1),
+        videoSourceType(rtc::VIDEO_SOURCE_CAMERA_PRIMARY) {}
 };
 
 class IFaceInfoObserver {
-public:
+ public:
   /**
    * Occurs when the face info is received.
    * @param outFaceInfo The output face info.
@@ -1939,7 +2086,8 @@
   unsigned int fileSize;
 
   RecorderInfo() : fileName(NULL), durationMs(0), fileSize(0) {}
-  RecorderInfo(const char* name, unsigned int dur, unsigned int size) : fileName(name), durationMs(dur), fileSize(size) {}
+  RecorderInfo(const char* name, unsigned int dur, unsigned int size)
+      : fileName(name), durationMs(dur), fileSize(size) {}
 };
 
 class IMediaRecorderObserver {
@@ -1949,30 +2097,35 @@
    *
    * @since v4.0.0
    *
-   * When the local audio and video recording state changes, the SDK triggers this callback to report the current
-   * recording state and the reason for the change.
+   * When the local audio and video recording state changes, the SDK triggers this callback to
+   * report the current recording state and the reason for the change.
    *
    * @param channelId The channel name.
    * @param uid ID of the user.
    * @param state The current recording state. See \ref agora::media::RecorderState "RecorderState".
-   * @param reason The reason for the state change. See \ref agora::media::RecorderReasonCode "RecorderReasonCode".
+   * @param reason The reason for the state change. See \ref agora::media::RecorderReasonCode
+   * "RecorderReasonCode".
    */
-  virtual void onRecorderStateChanged(const char* channelId, rtc::uid_t uid, RecorderState state, RecorderReasonCode reason) = 0;
+  virtual void onRecorderStateChanged(const char* channelId, rtc::uid_t uid, RecorderState state,
+                                      RecorderReasonCode reason) = 0;
   /**
    * Occurs when the recording information is updated.
    *
    * @since v4.0.0
    *
-   * After you successfully register this callback and enable the local audio and video recording, the SDK periodically triggers
-   * the `onRecorderInfoUpdated` callback based on the set value of `recorderInfoUpdateInterval`. This callback reports the
-   * filename, duration, and size of the current recording file.
+   * After you successfully register this callback and enable the local audio and video recording,
+   * the SDK periodically triggers the `onRecorderInfoUpdated` callback based on the set value of
+   * `recorderInfoUpdateInterval`. This callback reports the filename, duration, and size of the
+   * current recording file.
    *
    * @param channelId The channel name.
    * @param uid ID of the user.
-   * @param info Information about the recording file. See \ref agora::media::RecorderInfo "RecorderInfo".
+   * @param info Information about the recording file. See \ref agora::media::RecorderInfo
+   * "RecorderInfo".
    *
    */
-  virtual void onRecorderInfoUpdated(const char* channelId, rtc::uid_t uid, const RecorderInfo& info) = 0;
+  virtual void onRecorderInfoUpdated(const char* channelId, rtc::uid_t uid,
+                                     const RecorderInfo& info) = 0;
 
   virtual ~IMediaRecorderObserver() {}
 };
diff -u -b -r headers/rtc_4.4.0/include/IAgoraMediaEngine.h headers/rtc_4.5.0/include/IAgoraMediaEngine.h