+++ headers/rtc_4.5.0/include/AgoraBase.h	2024-10-31 14:11:09
@@ -559,7 +559,8 @@
   /**
    * 101: The App ID is invalid, usually because the data format of the App ID is incorrect.
    *
-   * Solution: Check the data format of your App ID. Ensure that you use the correct App ID to initialize the Agora service.
+   * Solution: Check the data format of your App ID. Ensure that you use the correct App ID to
+   * initialize the Agora service.
    */
   ERR_INVALID_APP_ID = 101,
   /**
@@ -578,9 +579,9 @@
    * - Timeout for token authorization: Once a token is generated, you must use it to access the
    * Agora service within 24 hours. Otherwise, the token times out and you can no longer use it.
    * - The token privilege expires: To generate a token, you need to set a timestamp for the token
-   * privilege to expire. For example, If you set it as seven days, the token expires seven days after
-   * its usage. In that case, you can no longer access the Agora service. The users cannot make calls,
-   * or are kicked out of the channel.
+   * privilege to expire. For example, If you set it as seven days, the token expires seven days
+   * after its usage. In that case, you can no longer access the Agora service. The users cannot
+   * make calls, or are kicked out of the channel.
    *
    * Solution: Regardless of whether token authorization times out or the token privilege expires,
    * you need to generate a new token on your server, and try to join the channel.
@@ -588,19 +589,19 @@
   ERR_TOKEN_EXPIRED = 109,
   /**
    * 110: The token is invalid, usually for one of the following reasons:
-   * - Did not provide a token when joining a channel in a situation where the project has enabled the
-   * App Certificate.
+   * - Did not provide a token when joining a channel in a situation where the project has enabled
+   * the App Certificate.
    * - Tried to join a channel with a token in a situation where the project has not enabled the App
    * Certificate.
-   * - The App ID, user ID and channel name that you use to generate the token on the server do not match
-   * those that you use when joining a channel.
+   * - The App ID, user ID and channel name that you use to generate the token on the server do not
+   * match those that you use when joining a channel.
    *
    * Solution:
-   * - Before joining a channel, check whether your project has enabled the App certificate. If yes, you
-   * must provide a token when joining a channel; if no, join a channel without a token.
-   * - When using a token to join a channel, ensure that the App ID, user ID, and channel name that you
-   * use to generate the token is the same as the App ID that you use to initialize the Agora service, and
-   * the user ID and channel name that you use to join the channel.
+   * - Before joining a channel, check whether your project has enabled the App certificate. If yes,
+   * you must provide a token when joining a channel; if no, join a channel without a token.
+   * - When using a token to join a channel, ensure that the App ID, user ID, and channel name that
+   * you use to generate the token is the same as the App ID that you use to initialize the Agora
+   * service, and the user ID and channel name that you use to join the channel.
    */
   ERR_INVALID_TOKEN = 110,
   /**
@@ -672,13 +673,15 @@
   ERR_LICENSE_CREDENTIAL_INVALID = 131,
 
   /**
-   * 134: The user account is invalid, usually because the data format of the user account is incorrect.
+   * 134: The user account is invalid, usually because the data format of the user account is
+   * incorrect.
    */
   ERR_INVALID_USER_ACCOUNT = 134,
 
   /** 157: The necessary dynamical library is not integrated. For example, if you call
-   * the \ref agora::rtc::IRtcEngine::enableDeepLearningDenoise "enableDeepLearningDenoise" but do not integrate the dynamical
-   * library for the deep-learning noise reduction into your project, the SDK reports this error code.
+   * the \ref agora::rtc::IRtcEngine::enableDeepLearningDenoise "enableDeepLearningDenoise" but do
+   * not integrate the dynamical library for the deep-learning noise reduction into your project,
+   * the SDK reports this error code.
    *
    */
   ERR_MODULE_NOT_FOUND = 157,
@@ -845,9 +848,9 @@
    */
   USER_OFFLINE_QUIT = 0,
   /**
-   * 1: The SDK times out and the user drops offline because no data packet was received within a certain
-   * period of time. If a user quits the call and the message is not passed to the SDK (due to an
-   * unreliable channel), the SDK assumes that the user drops offline.
+   * 1: The SDK times out and the user drops offline because no data packet was received within a
+   * certain period of time. If a user quits the call and the message is not passed to the SDK (due
+   * to an unreliable channel), the SDK assumes that the user drops offline.
    */
   USER_OFFLINE_DROPPED = 1,
   /**
@@ -999,7 +1002,6 @@
   FRAME_HEIGHT_540 = 540,
 };
 
-
 /**
  * Types of the video frame.
  */
@@ -1032,9 +1034,9 @@
   ORIENTATION_MODE_ADAPTIVE = 0,
   /**
    * 1: Landscape mode. In this mode, the SDK always outputs videos in landscape (horizontal) mode.
-   * If the captured video is in portrait mode, the video encoder crops it to fit the output. Applies
-   * to situations where the receiving end cannot process the rotational information. For example,
-   * CDN live streaming.
+   * If the captured video is in portrait mode, the video encoder crops it to fit the output.
+   * Applies to situations where the receiving end cannot process the rotational information. For
+   * example, CDN live streaming.
    */
   ORIENTATION_MODE_FIXED_LANDSCAPE = 1,
   /**
@@ -1051,9 +1053,16 @@
  */
 enum DEGRADATION_PREFERENCE {
   /**
-   * 0: (Default) Prefers to reduce the video frame rate while maintaining video quality during video
-   * encoding under limited bandwidth. This degradation preference is suitable for scenarios where
-   * video quality is prioritized.
+   * -1: (Default) SDK uses degradation preference according to setVideoScenario API settings, real-time network state and other relevant data information.
+   * If API setVideoScenario set video scenario to APPLICATION_SCENARIO_LIVESHOW, then MAINTAIN_BALANCED is used. If not, then MAINTAIN_RESOLUTION is used.
+   * Also if network state has changed, SDK may change this parameter between MAINTAIN_FRAMERATE„ÄÅMAINTAIN_BALANCED and MAINTAIN_RESOLUTION automatically to get the best QOE.
+   * We recommend using this option.
+  */
+  MAINTAIN_AUTO = -1,
+  /**
+   * 0: (Deprecated) Prefers to reduce the video frame rate while maintaining video quality during
+   * video encoding under limited bandwidth. This degradation preference is suitable for scenarios
+   * where video quality is prioritized.
    * @note In the COMMUNICATION channel profile, the resolution of the video sent may change, so
    * remote users need to handle this issue.
    */
@@ -1066,9 +1075,9 @@
   MAINTAIN_FRAMERATE = 1,
   /**
    * 2: Reduces the video frame rate and video quality simultaneously during video encoding under
-   * limited bandwidth. MAINTAIN_BALANCED has a lower reduction than MAINTAIN_QUALITY and MAINTAIN_FRAMERATE,
-   * and this preference is suitable for scenarios where both smoothness and video quality are a
-   * priority.
+   * limited bandwidth. MAINTAIN_BALANCED has a lower reduction than MAINTAIN_RESOLUTION and
+   * MAINTAIN_FRAMERATE, and this preference is suitable for scenarios where both smoothness and
+   * video quality are a priority.
    */
   MAINTAIN_BALANCED = 2,
   /**
@@ -1155,6 +1164,11 @@
  * The video codec types.
  */
 enum VIDEO_CODEC_TYPE {
+  /**
+   * 0: (Default) SDK will automatically adjust the codec type according to country and region or real-time network state and other relevant data information.
+   * Also if network state is changed, SDK may change codec automatically to get the best QOE.
+   * We recommend use this option.
+   */
   VIDEO_CODEC_NONE = 0,
   /**
    * 1: Standard VP8.
@@ -1170,11 +1184,13 @@
   VIDEO_CODEC_H265 = 3,
   /**
    * 6: Generic. This type is used for transmitting raw video data, such as encrypted video frames.
-   * The SDK returns this type of video frames in callbacks, and you need to decode and render the frames yourself.
+   * The SDK returns this type of video frames in callbacks, and you need to decode and render the
+   * frames yourself.
    */
   VIDEO_CODEC_GENERIC = 6,
   /**
    * 7: Generic H264.
+   * @deprecated This codec type is deprecated.
    */
   VIDEO_CODEC_GENERIC_H264 = 7,
   /**
@@ -1237,7 +1253,8 @@
    */
   TCcMode ccMode;
   /**
-   * The codec type used for the encoded images: \ref agora::rtc::VIDEO_CODEC_TYPE "VIDEO_CODEC_TYPE".
+   * The codec type used for the encoded images: \ref agora::rtc::VIDEO_CODEC_TYPE
+   * "VIDEO_CODEC_TYPE".
    */
   VIDEO_CODEC_TYPE codecType;
 
@@ -1249,12 +1266,14 @@
    * - \ref agora::rtc::STANDARD_BITRATE "STANDARD_BITRATE": (Recommended) Standard bitrate.
    *   - Communication profile: The encoding bitrate equals the base bitrate.
    *   - Live-broadcast profile: The encoding bitrate is twice the base bitrate.
-   * - \ref agora::rtc::COMPATIBLE_BITRATE "COMPATIBLE_BITRATE": Compatible bitrate. The bitrate stays the same
+   * - \ref agora::rtc::COMPATIBLE_BITRATE "COMPATIBLE_BITRATE": Compatible bitrate. The bitrate
+   stays the same
    * regardless of the profile.
    *
    * The Communication profile prioritizes smoothness, while the Live Broadcast
    * profile prioritizes video quality (requiring a higher bitrate). Agora
-   * recommends setting the bitrate mode as \ref agora::rtc::STANDARD_BITRATE "STANDARD_BITRATE" or simply to
+   * recommends setting the bitrate mode as \ref agora::rtc::STANDARD_BITRATE "STANDARD_BITRATE" or
+   simply to
    * address this difference.
    *
    * The following table lists the recommended video encoder configurations,
@@ -1262,7 +1281,8 @@
    * bitrate based on this table. If the bitrate you set is beyond the proper
    * range, the SDK automatically sets it to within the range.
 
-   | Resolution             | Frame Rate (fps) | Base Bitrate (Kbps, for Communication) | Live Bitrate (Kbps, for Live Broadcast)|
+   | Resolution             | Frame Rate (fps) | Base Bitrate (Kbps, for Communication) | Live
+   Bitrate (Kbps, for Live Broadcast)|
    |------------------------|------------------|----------------------------------------|----------------------------------------|
    | 160 &times; 120        | 15               | 65                                     | 130 |
    | 120 &times; 120        | 15               | 50                                     | 100 |
@@ -1299,10 +1319,7 @@
    */
   int targetBitrate;
 
-  SenderOptions()
-  : ccMode(CC_ENABLED),
-    codecType(VIDEO_CODEC_H265),
-    targetBitrate(6500) {}
+  SenderOptions() : ccMode(CC_ENABLED), codecType(VIDEO_CODEC_H265), targetBitrate(6500) {}
 };
 
 /**
@@ -1365,8 +1382,8 @@
    */
   AUDIO_ENCODING_TYPE_AAC_16000_LOW = 0x010101,
   /**
-   * AAC encoding format, 16000 Hz sampling rate, medium sound quality. A file with an audio duration
-   * of 10 minutes is approximately 2 MB after encoding.
+   * AAC encoding format, 16000 Hz sampling rate, medium sound quality. A file with an audio
+   * duration of 10 minutes is approximately 2 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_AAC_16000_MEDIUM = 0x010102,
   /**
@@ -1375,18 +1392,18 @@
    */
   AUDIO_ENCODING_TYPE_AAC_32000_LOW = 0x010201,
   /**
-   * AAC encoding format, 32000 Hz sampling rate, medium sound quality. A file with an audio duration
-   * of 10 minutes is approximately 2 MB after encoding.
+   * AAC encoding format, 32000 Hz sampling rate, medium sound quality. A file with an audio
+   * duration of 10 minutes is approximately 2 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_AAC_32000_MEDIUM = 0x010202,
   /**
-   * AAC encoding format, 32000 Hz sampling rate, high sound quality. A file with an audio duration of
-   * 10 minutes is approximately 3.5 MB after encoding.
+   * AAC encoding format, 32000 Hz sampling rate, high sound quality. A file with an audio duration
+   * of 10 minutes is approximately 3.5 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_AAC_32000_HIGH = 0x010203,
   /**
-   * AAC encoding format, 48000 Hz sampling rate, medium sound quality. A file with an audio duration
-   * of 10 minutes is approximately 2 MB after encoding.
+   * AAC encoding format, 48000 Hz sampling rate, medium sound quality. A file with an audio
+   * duration of 10 minutes is approximately 2 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_AAC_48000_MEDIUM = 0x010302,
   /**
@@ -1400,18 +1417,18 @@
    */
   AUDIO_ENCODING_TYPE_OPUS_16000_LOW = 0x020101,
   /**
-   * OPUS encoding format, 16000 Hz sampling rate, medium sound quality. A file with an audio duration
-   * of 10 minutes is approximately 2 MB after encoding.
+   * OPUS encoding format, 16000 Hz sampling rate, medium sound quality. A file with an audio
+   * duration of 10 minutes is approximately 2 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_OPUS_16000_MEDIUM = 0x020102,
   /**
-   * OPUS encoding format, 48000 Hz sampling rate, medium sound quality. A file with an audio duration
-   * of 10 minutes is approximately 2 MB after encoding.
+   * OPUS encoding format, 48000 Hz sampling rate, medium sound quality. A file with an audio
+   * duration of 10 minutes is approximately 2 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_OPUS_48000_MEDIUM = 0x020302,
   /**
-   * OPUS encoding format, 48000 Hz sampling rate, high sound quality. A file with an audio duration of
-   * 10 minutes is approximately 3.5 MB after encoding.
+   * OPUS encoding format, 48000 Hz sampling rate, high sound quality. A file with an audio duration
+   * of 10 minutes is approximately 3.5 MB after encoding.
    */
   AUDIO_ENCODING_TYPE_OPUS_48000_HIGH = 0x020303,
 };
@@ -1421,13 +1438,13 @@
  */
 enum WATERMARK_FIT_MODE {
   /**
-   * Use the `positionInLandscapeMode` and `positionInPortraitMode` values you set in #WatermarkOptions.
-   * The settings in `WatermarkRatio` are invalid.
+   * Use the `positionInLandscapeMode` and `positionInPortraitMode` values you set in
+   * #WatermarkOptions. The settings in `WatermarkRatio` are invalid.
    */
   FIT_MODE_COVER_POSITION,
   /**
-   * Use the value you set in `WatermarkRatio`. The settings in `positionInLandscapeMode` and `positionInPortraitMode`
-   * in `WatermarkOptions` are invalid.
+   * Use the value you set in `WatermarkRatio`. The settings in `positionInLandscapeMode` and
+   * `positionInPortraitMode` in `WatermarkOptions` are invalid.
    */
   FIT_MODE_USE_IMAGE_RATIO
 };
@@ -1436,9 +1453,7 @@
  * The advanced settings of encoded audio frame.
  */
 struct EncodedAudioFrameAdvancedSettings {
-  EncodedAudioFrameAdvancedSettings()
-    : speech(true),
-      sendEvenIfEmpty(true) {}
+  EncodedAudioFrameAdvancedSettings() : speech(true), sendEvenIfEmpty(true) {}
 
   /**
    * Determines whether the audio source is speech.
@@ -1504,7 +1519,8 @@
  * The definition of the AudioPcmDataInfo struct.
  */
 struct AudioPcmDataInfo {
-  AudioPcmDataInfo() : samplesPerChannel(0), channelNum(0), samplesOut(0), elapsedTimeMs(0), ntpTimeMs(0) {}
+  AudioPcmDataInfo()
+      : samplesPerChannel(0), channelNum(0), samplesOut(0), elapsedTimeMs(0), ntpTimeMs(0) {}
 
   AudioPcmDataInfo(const AudioPcmDataInfo& rhs)
       : samplesPerChannel(rhs.samplesPerChannel),
@@ -1605,18 +1621,17 @@
     VideoSubscriptionOptions() {}
 };
 
-
 /** The maximum length of the user account.
  */
-enum MAX_USER_ACCOUNT_LENGTH_TYPE
-{
+enum MAX_USER_ACCOUNT_LENGTH_TYPE {
   /** The maximum length of the user account is 256 bytes.
    */
   MAX_USER_ACCOUNT_LENGTH = 256
 };
 
 /**
- * The definition of the EncodedVideoFrameInfo struct, which contains the information of the external encoded video frame.
+ * The definition of the EncodedVideoFrameInfo struct, which contains the information of the
+ * external encoded video frame.
  */
 struct EncodedVideoFrameInfo {
   EncodedVideoFrameInfo()
@@ -1669,7 +1684,8 @@
    */
   uid_t uid;
   /**
-   * The codec type of the local video stream. See #VIDEO_CODEC_TYPE. The default value is `VIDEO_CODEC_H265 (3)`.
+   * The codec type of the local video stream. See #VIDEO_CODEC_TYPE. The default value is
+   * `VIDEO_CODEC_H265 (3)`.
    */
   VIDEO_CODEC_TYPE codecType;
   /**
@@ -1717,22 +1733,29 @@
 };
 
 /**
-* Video compression preference.
-*/
+ * Video compression preference.
+ */
 enum COMPRESSION_PREFERENCE {
   /**
-  * (Default) Low latency is preferred, usually used in real-time communication where low latency is the number one priority.
+   * (Default) SDK uses compression preference according to setVideoScenario API settings, real-time network state and other relevant data information.
+   * If API setVideoScenario set video scenario to APPLICATION_SCENARIO_LIVESHOW, then PREFER_QUALITY is used. If not, then PREFER_LOW_LATENCY is used.
+   * Also if network state has changed, SDK may change this parameter between PREFER_QUALITY and PREFER_LOW_LATENCY automatically to get the best QOE.
+   * We recommend using this option.
   */
-  PREFER_LOW_LATENCY,
+  PREFER_COMPRESSION_AUTO = -1,
   /**
+   * Prefer low latency, usually used in real-time communication where low latency is the number one priority.
+  */
+  PREFER_LOW_LATENCY = 0,
+  /**
   * Prefer quality in sacrifice of a degree of latency, usually around 30ms ~ 150ms, depends target fps
   */
-  PREFER_QUALITY,
+  PREFER_QUALITY = 1,
 };
 
 /**
-* The video encoder type preference.
-*/
+ * The video encoder type preference.
+ */
 enum ENCODING_PREFERENCE {
   /**
    *Default .
@@ -1752,7 +1775,6 @@
  * The definition of the AdvanceOptions struct.
  */
 struct AdvanceOptions {
-
   /**
    * The video encoder type preference..
    */
@@ -1770,7 +1792,7 @@
   bool encodeAlpha;
 
   AdvanceOptions() : encodingPreference(PREFER_AUTO), 
-                     compressionPreference(PREFER_LOW_LATENCY),
+                     compressionPreference(PREFER_COMPRESSION_AUTO),
                      encodeAlpha(false) {}
 
   AdvanceOptions(ENCODING_PREFERENCE encoding_preference, 
@@ -1785,7 +1807,6 @@
            compressionPreference == rhs.compressionPreference &&
            encodeAlpha == rhs.encodeAlpha;
   }
-
 };
 
 /**
@@ -1818,6 +1839,30 @@
 };
 #endif
 
+enum VIDEO_MODULE_TYPE {
+  /** Video capture module */
+  VIDEO_MODULE_CAPTURER = 0,
+  /** Video software encoder module */
+  VIDEO_MODULE_SOFTWARE_ENCODER = 1,
+  /** Video hardware encoder module */
+  VIDEO_MODULE_HARDWARE_ENCODER = 2,
+  /** Video software decoder module */
+  VIDEO_MODULE_SOFTWARE_DECODER = 3,
+  /** Video hardware decoder module */
+  VIDEO_MODULE_HARDWARE_DECODER = 4,
+  /** Video render module */
+  VIDEO_MODULE_RENDERER = 5,
+};
+ 
+enum HDR_CAPABILITY {
+  /** The result of static check is not reliable, by defualt*/
+  HDR_CAPABILITY_UNKNOWN = -1,
+  /** The module you query doesn't support HDR */
+  HDR_CAPABILITY_UNSUPPORTED = 0,
+  /** The module you query supports HDR */
+  HDR_CAPABILITY_SUPPORTED = 1,
+};
+
 /** Supported codec type bit mask. */
 enum CODEC_CAP_MASK {
   /** 0: No codec support. */
@@ -1840,7 +1885,9 @@
   VIDEO_CODEC_CAPABILITY_LEVEL hwDecodingLevel;
   VIDEO_CODEC_CAPABILITY_LEVEL swDecodingLevel;
 
-  CodecCapLevels(): hwDecodingLevel(CODEC_CAPABILITY_LEVEL_UNSPECIFIED), swDecodingLevel(CODEC_CAPABILITY_LEVEL_UNSPECIFIED) {}
+  CodecCapLevels()
+      : hwDecodingLevel(CODEC_CAPABILITY_LEVEL_UNSPECIFIED),
+        swDecodingLevel(CODEC_CAPABILITY_LEVEL_UNSPECIFIED) {}
 };
 
 /** The codec support information. */
@@ -1852,10 +1899,11 @@
   /** The codec capability level, estimated based on the device hardware.*/
   CodecCapLevels codecLevels;
 
-  CodecCapInfo(): codecType(VIDEO_CODEC_NONE), codecCapMask(0) {}
+  CodecCapInfo() : codecType(VIDEO_CODEC_NONE), codecCapMask(0) {}
 };
 
-/** FocalLengthInfo contains the IDs of the front and rear cameras, along with the wide-angle types. */
+/** FocalLengthInfo contains the IDs of the front and rear cameras, along with the wide-angle types.
+ */
 struct FocalLengthInfo {
   /** The camera direction. */
   int cameraDirection;
@@ -1882,21 +1930,22 @@
   /**
    * The bitrate (Kbps) of the video.
    *
-   * Refer to the **Video Bitrate Table** below and set your bitrate. If you set a bitrate beyond the
-   * proper range, the SDK automatically adjusts it to a value within the range. You can also choose
-   * from the following options:
+   * Refer to the **Video Bitrate Table** below and set your bitrate. If you set a bitrate beyond
+   * the proper range, the SDK automatically adjusts it to a value within the range. You can also
+   * choose from the following options:
    *
-   * - #STANDARD_BITRATE: (Recommended) Standard bitrate mode. In this mode, the bitrates differ between
-   * the Live Broadcast and Communication profiles:
+   * - #STANDARD_BITRATE: (Recommended) Standard bitrate mode. In this mode, the bitrates differ
+   * between the Live Broadcast and Communication profiles:
    *   - In the Communication profile, the video bitrate is the same as the base bitrate.
    *   - In the Live Broadcast profile, the video bitrate is twice the base bitrate.
-   * - #COMPATIBLE_BITRATE: Compatible bitrate mode. The compatible bitrate mode. In this mode, the bitrate
-   * stays the same regardless of the profile. If you choose this mode for the Live Broadcast profile,
-   * the video frame rate may be lower than the set value.
+   * - #COMPATIBLE_BITRATE: Compatible bitrate mode. The compatible bitrate mode. In this mode, the
+   * bitrate stays the same regardless of the profile. If you choose this mode for the Live
+   * Broadcast profile, the video frame rate may be lower than the set value.
    *
-   * Agora uses different video codecs for different profiles to optimize the user experience. For example,
-   * the communication profile prioritizes the smoothness while the live-broadcast profile prioritizes the
-   * video quality (a higher bitrate). Therefore, We recommend setting this parameter as #STANDARD_BITRATE.
+   * Agora uses different video codecs for different profiles to optimize the user experience. For
+   * example, the communication profile prioritizes the smoothness while the live-broadcast profile
+   * prioritizes the video quality (a higher bitrate). Therefore, We recommend setting this
+   * parameter as #STANDARD_BITRATE.
    *
    * | Resolution             | Frame Rate (fps) | Base Bitrate (Kbps) | Live Bitrate (Kbps)|
    * |------------------------|------------------|---------------------|--------------------|
@@ -1964,7 +2013,8 @@
 
   /**
    * The mirror mode is disabled by default
-   * If mirror_type is set to VIDEO_MIRROR_MODE_ENABLED, then the video frame would be mirrored before encoding.
+   * If mirror_type is set to VIDEO_MIRROR_MODE_ENABLED, then the video frame would be mirrored
+   * before encoding.
    */
   VIDEO_MIRROR_MODE_TYPE mirrorMode;
 
@@ -1980,9 +2030,9 @@
       bitrate(b),
       minBitrate(DEFAULT_MIN_BITRATE),
       orientationMode(m),
-      degradationPreference(MAINTAIN_QUALITY),
+      degradationPreference(MAINTAIN_AUTO),
       mirrorMode(mirror),
-      advanceOptions(PREFER_AUTO, PREFER_LOW_LATENCY, false) {}
+      advanceOptions(PREFER_AUTO, PREFER_COMPRESSION_AUTO, false) {}
   VideoEncoderConfiguration(int width, int height, int f, int b, ORIENTATION_MODE m, VIDEO_MIRROR_MODE_TYPE mirror = VIDEO_MIRROR_MODE_DISABLED)
     : codecType(VIDEO_CODEC_NONE),
       dimensions(width, height),
@@ -1990,9 +2040,9 @@
       bitrate(b),
       minBitrate(DEFAULT_MIN_BITRATE),
       orientationMode(m),
-      degradationPreference(MAINTAIN_QUALITY),
+      degradationPreference(MAINTAIN_AUTO),
       mirrorMode(mirror),
-      advanceOptions(PREFER_AUTO, PREFER_LOW_LATENCY, false) {}
+      advanceOptions(PREFER_AUTO, PREFER_COMPRESSION_AUTO, false) {}
   VideoEncoderConfiguration(const VideoEncoderConfiguration& config)
       : codecType(config.codecType),
         dimensions(config.dimensions),
@@ -2010,9 +2060,9 @@
       bitrate(STANDARD_BITRATE),
       minBitrate(DEFAULT_MIN_BITRATE),
       orientationMode(ORIENTATION_MODE_ADAPTIVE),
-      degradationPreference(MAINTAIN_QUALITY),
+      degradationPreference(MAINTAIN_AUTO),
       mirrorMode(VIDEO_MIRROR_MODE_DISABLED),
-      advanceOptions(PREFER_AUTO, PREFER_LOW_LATENCY, false) {}
+      advanceOptions(PREFER_AUTO, PREFER_COMPRESSION_AUTO, false) {}
 
   VideoEncoderConfiguration& operator=(const VideoEncoderConfiguration& rhs) {
     if (this == &rhs) return *this;
@@ -2040,9 +2090,9 @@
    *
    * When you set the data packet to synchronize with the audio, then if the data packet delay is
    * within the audio delay, the SDK triggers the `onStreamMessage` callback when the synchronized
-   * audio packet is played out. Do not set this parameter as true if you need the receiver to receive
-   * the data packet immediately. Agora recommends that you set this parameter to `true` only when you
-   * need to implement specific functions, for example lyric synchronization.
+   * audio packet is played out. Do not set this parameter as true if you need the receiver to
+   * receive the data packet immediately. Agora recommends that you set this parameter to `true`
+   * only when you need to implement specific functions, for example lyric synchronization.
    */
   bool syncWithAudio;
   /**
@@ -2050,7 +2100,8 @@
    * - `true`: Guarantee that the receiver receives the data in the sent order.
    * - `false`: Do not guarantee that the receiver receives the data in the sent order.
    *
-   * Do not set this parameter as `true` if you need the receiver to receive the data packet immediately.
+   * Do not set this parameter as `true` if you need the receiver to receive the data packet
+   * immediately.
    */
   bool ordered;
 };
@@ -2082,7 +2133,8 @@
    */
   VideoDimensions dimensions;
   /**
-   * The video bitrate (Kbps), represented by an instantaneous value. The default value of the log level is 5.
+   * The video bitrate (Kbps), represented by an instantaneous value. The default value of the log
+   * level is 5.
    */
   int kBitrate;
   /**
@@ -2187,28 +2239,31 @@
 /**
  * The position and size of the watermark on the screen.
  *
- * The position and size of the watermark on the screen are determined by `xRatio`, `yRatio`, and `widthRatio`:
- * - (`xRatio`, `yRatio`) refers to the coordinates of the upper left corner of the watermark, which determines
- *  the distance from the upper left corner of the watermark to the upper left corner of the screen.
- * The `widthRatio` determines the width of the watermark.
+ * The position and size of the watermark on the screen are determined by `xRatio`, `yRatio`, and
+ * `widthRatio`:
+ * - (`xRatio`, `yRatio`) refers to the coordinates of the upper left corner of the watermark, which
+ * determines the distance from the upper left corner of the watermark to the upper left corner of
+ * the screen. The `widthRatio` determines the width of the watermark.
  */
 struct WatermarkRatio {
   /**
    * The x-coordinate of the upper left corner of the watermark. The horizontal position relative to
-   * the origin, where the upper left corner of the screen is the origin, and the x-coordinate is the
-   * upper left corner of the watermark. The value range is [0.0,1.0], and the default value is 0.
+   * the origin, where the upper left corner of the screen is the origin, and the x-coordinate is
+   * the upper left corner of the watermark. The value range is [0.0,1.0], and the default value is
+   * 0.
    */
   float xRatio;
   /**
-   * The y-coordinate of the upper left corner of the watermark. The vertical position relative to the
-   * origin, where the upper left corner of the screen is the origin, and the y-coordinate is the upper
-   * left corner of the screen. The value range is [0.0,1.0], and the default value is 0.
+   * The y-coordinate of the upper left corner of the watermark. The vertical position relative to
+   * the origin, where the upper left corner of the screen is the origin, and the y-coordinate is
+   * the upper left corner of the screen. The value range is [0.0,1.0], and the default value is 0.
    */
   float yRatio;
   /**
-   * The width of the watermark. The SDK calculates the height of the watermark proportionally according
-   * to this parameter value to ensure that the enlarged or reduced watermark image is not distorted.
-   * The value range is [0,1], and the default value is 0, which means no watermark is displayed.
+   * The width of the watermark. The SDK calculates the height of the watermark proportionally
+   * according to this parameter value to ensure that the enlarged or reduced watermark image is not
+   * distorted. The value range is [0,1], and the default value is 0, which means no watermark is
+   * displayed.
    */
   float widthRatio;
 
@@ -2321,7 +2376,8 @@
    * The app CPU usage (%).
    * @note
    * - The value of `cpuAppUsage` is always reported as 0 in the `onLeaveChannel` callback.
-   * - As of Android 8.1, you cannot get the CPU usage from this attribute due to system limitations.
+   * - As of Android 8.1, you cannot get the CPU usage from this attribute due to system
+   * limitations.
    */
   double cpuAppUsage;
   /**
@@ -2331,13 +2387,15 @@
    * value = (100 - System Idle Progress in Task Manager)/100.
    * @note
    * - The value of `cpuTotalUsage` is always reported as 0 in the `onLeaveChannel` callback.
-   * - As of Android 8.1, you cannot get the CPU usage from this attribute due to system limitations.
+   * - As of Android 8.1, you cannot get the CPU usage from this attribute due to system
+   * limitations.
    */
   double cpuTotalUsage;
   /**
    * The round-trip time delay from the client to the local router.
-   * @note On Android, to get `gatewayRtt`, ensure that you add the `android.permission.ACCESS_WIFI_STATE`
-   * permission after `</application>` in the `AndroidManifest.xml` file in your project.
+   * @note On Android, to get `gatewayRtt`, ensure that you add the
+   * `android.permission.ACCESS_WIFI_STATE` permission after `</application>` in the
+   * `AndroidManifest.xml` file in your project.
    */
   int gatewayRtt;
   /**
@@ -2464,7 +2522,8 @@
 };
 
 /**
- * Quality change of the local video in terms of target frame rate and target bit rate since last count.
+ * Quality change of the local video in terms of target frame rate and target bit rate since last
+ * count.
  */
 enum QUALITY_ADAPT_INDICATION {
   /**
@@ -2482,11 +2541,10 @@
 };
 
 /**
- * The latency level of an audience member in interactive live streaming. This enum takes effect only
- * when the user role is set to `CLIENT_ROLE_AUDIENCE`.
+ * The latency level of an audience member in interactive live streaming. This enum takes effect
+ * only when the user role is set to `CLIENT_ROLE_AUDIENCE`.
  */
-enum AUDIENCE_LATENCY_LEVEL_TYPE
-{
+enum AUDIENCE_LATENCY_LEVEL_TYPE {
   /**
    * 1: Low latency.
    */
@@ -2500,15 +2558,14 @@
 /**
  * The detailed options of a user.
  */
-struct ClientRoleOptions
-{
+struct ClientRoleOptions {
   /**
-   * The latency level of an audience member in interactive live streaming. See `AUDIENCE_LATENCY_LEVEL_TYPE`.
+   * The latency level of an audience member in interactive live streaming. See
+   * `AUDIENCE_LATENCY_LEVEL_TYPE`.
    */
   AUDIENCE_LATENCY_LEVEL_TYPE audienceLatencyLevel;
 
-  ClientRoleOptions()
-    : audienceLatencyLevel(AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY) {}
+  ClientRoleOptions() : audienceLatencyLevel(AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY) {}
 };
 
 /**
@@ -2542,8 +2599,8 @@
    */
   WIRELESS_SIGNAL_POOR = 4,
   /**
-   * 8: The local user enables both Wi-Fi and bluetooth, and their signals interfere with each other.
-   * As a result, audio transmission quality is undermined.
+   * 8: The local user enables both Wi-Fi and bluetooth, and their signals interfere with each
+   * other. As a result, audio transmission quality is undermined.
    */
   WIFI_BLUETOOTH_COEXIST = 8,
 };
@@ -2574,9 +2631,10 @@
    * 0: The default audio profile.
    * - For the Communication profile:
    *   - Windows: A sample rate of 16 kHz, audio encoding, mono, and a bitrate of up to 16 Kbps.
-   *   - Android/macOS/iOS: A sample rate of 32 kHz, audio encoding, mono, and a bitrate of up to 18 Kbps.
-   * of up to 16 Kbps.
-   * - For the Live-broadcast profile: A sample rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps.
+   *   - Android/macOS/iOS: A sample rate of 32 kHz, audio encoding, mono, and a bitrate of up to 18
+   * Kbps. of up to 16 Kbps.
+   * - For the Live-broadcast profile: A sample rate of 48 kHz, music encoding, mono, and a bitrate
+   * of up to 64 Kbps.
    */
   AUDIO_PROFILE_DEFAULT = 0,
   /**
@@ -2590,8 +2648,8 @@
   /**
    * 3: A sample rate of 48 kHz, music encoding, stereo, and a bitrate of up to 80 Kbps.
    *
-   * To implement stereo audio, you also need to call `setAdvancedAudioOptions` and set `audioProcessingChannels`
-   * to `AUDIO_PROCESSING_STEREO` in `AdvancedAudioOptions`.
+   * To implement stereo audio, you also need to call `setAdvancedAudioOptions` and set
+   * `audioProcessingChannels` to `AUDIO_PROCESSING_STEREO` in `AdvancedAudioOptions`.
    */
   AUDIO_PROFILE_MUSIC_STANDARD_STEREO = 3,
   /**
@@ -2601,8 +2659,8 @@
   /**
    * 5: A sample rate of 48 kHz, music encoding, stereo, and a bitrate of up to 128 Kbps.
    *
-   * To implement stereo audio, you also need to call `setAdvancedAudioOptions` and set `audioProcessingChannels`
-   * to `AUDIO_PROCESSING_STEREO` in `AdvancedAudioOptions`.
+   * To implement stereo audio, you also need to call `setAdvancedAudioOptions` and set
+   * `audioProcessingChannels` to `AUDIO_PROCESSING_STEREO` in `AdvancedAudioOptions`.
    */
   AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO = 5,
   /**
@@ -2634,7 +2692,8 @@
    */
   AUDIO_SCENARIO_CHATROOM = 5,
   /**
-   * 7: Real-time chorus scenario, where users have good network conditions and require ultra-low latency.
+   * 7: Real-time chorus scenario, where users have good network conditions and require ultra-low
+   * latency.
    */
   AUDIO_SCENARIO_CHORUS = 7,
   /**
@@ -2651,7 +2710,7 @@
  * The format of the video frame.
  */
 struct VideoFormat {
-  OPTIONAL_ENUM_SIZE_T {
+  OPTIONAL_ENUM_SIZE_T{
       /** The maximum value (px) of the width. */
       kMaxWidthInPixels = 3840,
       /** The maximum value (px) of the height. */
@@ -2687,9 +2746,7 @@
   bool operator==(const VideoFormat& fmt) const {
     return width == fmt.width && height == fmt.height && fps == fmt.fps;
   }
-  bool operator!=(const VideoFormat& fmt) const {
-    return !operator==(fmt);
-  }
+  bool operator!=(const VideoFormat& fmt) const { return !operator==(fmt); }
 };
 
 /**
@@ -2742,7 +2799,6 @@
   SCREEN_SCENARIO_RDC = 4,
 };
 
-
 /**
  * The video application scenario type.
  */
@@ -2759,6 +2815,10 @@
    * 2: Video Call Scenario. This scenario is used to optimize the video experience in video application, like 1v1 video call.
    */
   APPLICATION_SCENARIO_1V1 = 2,
+  /**
+   * 3: Live Show Scenario. This scenario is used to optimize the video experience in video live show.
+   */
+  APPLICATION_SCENARIO_LIVESHOW = 3,
 };
 
 /**
@@ -2789,7 +2849,8 @@
  */
 enum CAPTURE_BRIGHTNESS_LEVEL_TYPE {
   /** -1: The SDK does not detect the brightness level of the video image.
-   * Wait a few seconds to get the brightness level from `CAPTURE_BRIGHTNESS_LEVEL_TYPE` in the next callback.
+   * Wait a few seconds to get the brightness level from `CAPTURE_BRIGHTNESS_LEVEL_TYPE` in the next
+   * callback.
    */
   CAPTURE_BRIGHTNESS_LEVEL_INVALID = -1,
   /** 0: The brightness level of the video image is normal.
@@ -2855,7 +2916,8 @@
    */
   LOCAL_AUDIO_STREAM_REASON_OK = 0,
   /**
-   * 1: No specified reason for the local audio failure. Remind your users to try to rejoin the channel.
+   * 1: No specified reason for the local audio failure. Remind your users to try to rejoin the
+   * channel.
    */
   LOCAL_AUDIO_STREAM_REASON_FAILURE = 1,
   /**
@@ -2968,7 +3030,7 @@
    */
   LOCAL_VIDEO_STREAM_REASON_DEVICE_NOT_FOUND = 8,
   /**
-   *  9: (macOS only) The video capture device currently in use is disconnected (such as being
+   *  9: (macOS and Windows only) The video capture device currently in use is disconnected (such as being
    * unplugged).
    */
   LOCAL_VIDEO_STREAM_REASON_DEVICE_DISCONNECTED = 9,
@@ -2983,8 +3045,8 @@
    */
   LOCAL_VIDEO_STREAM_REASON_DEVICE_INTERRUPT = 14,
   /**
-   * 15: (Android only) The device may need to be shut down and restarted to restore camera function, 
-   * or there may be a persistent hardware problem.
+   * 15: (Android only) The device may need to be shut down and restarted to restore camera
+   * function, or there may be a persistent hardware problem.
    */
   LOCAL_VIDEO_STREAM_REASON_DEVICE_FATAL_ERROR = 15,
   /**
@@ -3021,12 +3083,13 @@
   /** 22: No permision to capture screen. */
   LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_NO_PERMISSION = 22,
   /**
-   * 24: (Windows Only) An unexpected error (possibly due to window block failure) occurs during the screen 
-   * sharing process, resulting in performance degradation. However, the screen sharing process itself is 
-   * functioning normally.
+   * 24: (Windows Only) An unexpected error (possibly due to window block failure) occurs during the
+   * screen sharing process, resulting in performance degradation. However, the screen sharing
+   * process itself is functioning normally.
    */
   LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_AUTO_FALLBACK = 24,
-  /** 25: (Windows only) The local screen capture window is currently hidden and not visible on the desktop. */
+  /** 25: (Windows only) The local screen capture window is currently hidden and not visible on the
+     desktop. */
   LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_HIDDEN = 25,
   /** 26: (Windows only) The local screen capture window is recovered from its hidden state. */
   LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN = 26,
@@ -3050,24 +3113,25 @@
 /**
  * Remote audio states.
  */
-enum REMOTE_AUDIO_STATE
-{
+enum REMOTE_AUDIO_STATE {
   /**
    * 0: The remote audio is in the default state. The SDK reports this state in the case of
    * `REMOTE_AUDIO_REASON_LOCAL_MUTED(3)`, `REMOTE_AUDIO_REASON_REMOTE_MUTED(5)`, or
    * `REMOTE_AUDIO_REASON_REMOTE_OFFLINE(7)`.
    */
-  REMOTE_AUDIO_STATE_STOPPED = 0,  // Default state, audio is started or remote user disabled/muted audio stream
+  REMOTE_AUDIO_STATE_STOPPED =
+      0,  // Default state, audio is started or remote user disabled/muted audio stream
   /**
    * 1: The first remote audio packet is received.
    */
   REMOTE_AUDIO_STATE_STARTING = 1,  // The first audio frame packet has been received
   /**
-   * 2: The remote audio stream is decoded and plays normally. The SDK reports this state in the case of
-   * `REMOTE_AUDIO_REASON_NETWORK_RECOVERY(2)`, `REMOTE_AUDIO_REASON_LOCAL_UNMUTED(4)`, or
+   * 2: The remote audio stream is decoded and plays normally. The SDK reports this state in the
+   * case of `REMOTE_AUDIO_REASON_NETWORK_RECOVERY(2)`, `REMOTE_AUDIO_REASON_LOCAL_UNMUTED(4)`, or
    * `REMOTE_AUDIO_REASON_REMOTE_UNMUTED(6)`.
    */
-  REMOTE_AUDIO_STATE_DECODING = 2,  // The first remote audio frame has been decoded or fronzen state ends
+  REMOTE_AUDIO_STATE_DECODING =
+      2,  // The first remote audio frame has been decoded or fronzen state ends
   /**
    * 3: The remote audio is frozen. The SDK reports this state in the case of
    * `REMOTE_AUDIO_REASON_NETWORK_CONGESTION(1)`.
@@ -3083,8 +3147,7 @@
 /**
  * Reasons for the remote audio state change.
  */
-enum REMOTE_AUDIO_STATE_REASON
-{
+enum REMOTE_AUDIO_STATE_REASON {
   /**
    * 0: The SDK reports this reason when the video state changes.
    */
@@ -3138,7 +3201,8 @@
   /**
    * 0: The remote video is in the default state. The SDK reports this state in the case of
    * `REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED (3)`, `REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED (5)`,
-   * `REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE (7)`, or `REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK (8)`.
+   * `REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE (7)`, or `REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK
+   * (8)`.
    */
   REMOTE_VIDEO_STATE_STOPPED = 0,
   /**
@@ -3146,9 +3210,10 @@
    */
   REMOTE_VIDEO_STATE_STARTING = 1,
   /**
-   * 2: The remote video stream is decoded and plays normally. The SDK reports this state in the case of
-   * `REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY (2)`, `REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED (4)`,
-   * `REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED (6)`, or `REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY (9)`.
+   * 2: The remote video stream is decoded and plays normally. The SDK reports this state in the
+   * case of `REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY (2)`,
+   * `REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED (4)`, `REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED (6)`,
+   * or `REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY (9)`.
    */
   REMOTE_VIDEO_STATE_DECODING = 2,
   /** 3: The remote video is frozen, probably due to
@@ -3248,10 +3313,14 @@
  */
 struct VideoTrackInfo {
   VideoTrackInfo()
-  : isLocal(false), ownerUid(0), trackId(0), channelId(OPTIONAL_NULLPTR)
-  , codecType(VIDEO_CODEC_H265)
-  , encodedFrameOnly(false), sourceType(VIDEO_SOURCE_CAMERA_PRIMARY)
-  , observationPosition(agora::media::base::POSITION_POST_CAPTURER) {}
+      : isLocal(false),
+        ownerUid(0),
+        trackId(0),
+        channelId(OPTIONAL_NULLPTR),
+        codecType(VIDEO_CODEC_H265),
+        encodedFrameOnly(false),
+        sourceType(VIDEO_SOURCE_CAMERA_PRIMARY),
+        observationPosition(agora::media::base::POSITION_POST_CAPTURER) {}
   /**
    * Whether the video track is local or remote.
    * - true: The video track is local.
@@ -3291,7 +3360,8 @@
 };
 
 /**
- * The downscale level of the remote video stream . The higher the downscale level, the more the video downscales.
+ * The downscale level of the remote video stream . The higher the downscale level, the more the
+ * video downscales.
  */
 enum REMOTE_VIDEO_DOWNSCALE_LEVEL {
   /**
@@ -3340,7 +3410,8 @@
    * @note
    * - The `vad` parameter does not report the voice activity status of remote users. In a remote
    * user's callback, the value of `vad` is always 1.
-   * - To use this parameter, you must set `reportVad` to true when calling `enableAudioVolumeIndication`.
+   * - To use this parameter, you must set `reportVad` to true when calling
+   * `enableAudioVolumeIndication`.
    */
   unsigned int vad;
   /**
@@ -3464,7 +3535,8 @@
    */
   VIDEO_CODEC_PROFILE_BASELINE = 66,
   /**
-   * 77: Main video codec profile. Generally used in mainstream electronics, such as MP4 players, portable video players, PSP, and iPads.
+   * 77: Main video codec profile. Generally used in mainstream electronics, such as MP4 players,
+   * portable video players, PSP, and iPads.
    */
   VIDEO_CODEC_PROFILE_MAIN = 77,
   /**
@@ -3473,7 +3545,6 @@
   VIDEO_CODEC_PROFILE_HIGH = 100,
 };
 
-
 /**
  * Self-defined audio codec profile.
  */
@@ -3495,8 +3566,7 @@
 /**
  * Local audio statistics.
  */
-struct LocalAudioStats
-{
+struct LocalAudioStats {
   /**
    * The number of audio channels.
    */
@@ -3514,7 +3584,8 @@
    */
   int internalCodec;
   /**
-   * The packet loss rate (%) from the local client to the Agora server before applying the anti-packet loss strategies.
+   * The packet loss rate (%) from the local client to the Agora server before applying the
+   * anti-packet loss strategies.
    */
   unsigned short txPacketLossRate;
   /**
@@ -3535,35 +3606,45 @@
   int aecEstimatedDelay;
 };
 
-
 /**
  * States of the Media Push.
  */
 enum RTMP_STREAM_PUBLISH_STATE {
   /**
-   * 0: The Media Push has not started or has ended. This state is also triggered after you remove a RTMP or RTMPS stream from the CDN by calling `removePublishStreamUrl`.
+   * 0: The Media Push has not started or has ended. This state is also triggered after you remove a
+   * RTMP or RTMPS stream from the CDN by calling `removePublishStreamUrl`.
    */
   RTMP_STREAM_PUBLISH_STATE_IDLE = 0,
   /**
-   * 1: The SDK is connecting to Agora's streaming server and the CDN server. This state is triggered after you call the `addPublishStreamUrl` method.
+   * 1: The SDK is connecting to Agora's streaming server and the CDN server. This state is
+   * triggered after you call the `addPublishStreamUrl` method.
    */
   RTMP_STREAM_PUBLISH_STATE_CONNECTING = 1,
   /**
-   * 2: The RTMP or RTMPS streaming publishes. The SDK successfully publishes the RTMP or RTMPS streaming and returns this state.
+   * 2: The RTMP or RTMPS streaming publishes. The SDK successfully publishes the RTMP or RTMPS
+   * streaming and returns this state.
    */
   RTMP_STREAM_PUBLISH_STATE_RUNNING = 2,
   /**
-   * 3: The RTMP or RTMPS streaming is recovering. When exceptions occur to the CDN, or the streaming is interrupted, the SDK tries to resume RTMP or RTMPS streaming and returns this state.
-   * - If the SDK successfully resumes the streaming, #RTMP_STREAM_PUBLISH_STATE_RUNNING (2) returns.
-   * - If the streaming does not resume within 60 seconds or server errors occur, #RTMP_STREAM_PUBLISH_STATE_FAILURE (4) returns. You can also reconnect to the server by calling the `removePublishStreamUrl` and `addPublishStreamUrl` methods.
+   * 3: The RTMP or RTMPS streaming is recovering. When exceptions occur to the CDN, or the
+   * streaming is interrupted, the SDK tries to resume RTMP or RTMPS streaming and returns this
+   * state.
+   * - If the SDK successfully resumes the streaming, #RTMP_STREAM_PUBLISH_STATE_RUNNING (2)
+   * returns.
+   * - If the streaming does not resume within 60 seconds or server errors occur,
+   * #RTMP_STREAM_PUBLISH_STATE_FAILURE (4) returns. You can also reconnect to the server by calling
+   * the `removePublishStreamUrl` and `addPublishStreamUrl` methods.
    */
   RTMP_STREAM_PUBLISH_STATE_RECOVERING = 3,
   /**
-   * 4: The RTMP or RTMPS streaming fails. See the `errCode` parameter for the detailed error information. You can also call the `addPublishStreamUrl` method to publish the RTMP or RTMPS streaming again.
+   * 4: The RTMP or RTMPS streaming fails. See the `errCode` parameter for the detailed error
+   * information. You can also call the `addPublishStreamUrl` method to publish the RTMP or RTMPS
+   * streaming again.
    */
   RTMP_STREAM_PUBLISH_STATE_FAILURE = 4,
   /**
-   * 5: The SDK is disconnecting to Agora's streaming server and the CDN server. This state is triggered after you call the `removePublishStreamUrl` method.
+   * 5: The SDK is disconnecting to Agora's streaming server and the CDN server. This state is
+   * triggered after you call the `removePublishStreamUrl` method.
    */
   RTMP_STREAM_PUBLISH_STATE_DISCONNECTING = 5,
 };
@@ -3577,8 +3658,10 @@
    */
   RTMP_STREAM_PUBLISH_REASON_OK = 0,
   /**
-   * 1: Invalid argument used. If, for example, you do not call the `setLiveTranscoding` method to configure the LiveTranscoding parameters before calling the addPublishStreamUrl method,
-   * the SDK returns this error. Check whether you set the parameters in the `setLiveTranscoding` method properly.
+   * 1: Invalid argument used. If, for example, you do not call the `setLiveTranscoding` method to
+   * configure the LiveTranscoding parameters before calling the addPublishStreamUrl method, the SDK
+   * returns this error. Check whether you set the parameters in the `setLiveTranscoding` method
+   * properly.
    */
   RTMP_STREAM_PUBLISH_REASON_INVALID_ARGUMENT = 1,
   /**
@@ -3586,11 +3669,13 @@
    */
   RTMP_STREAM_PUBLISH_REASON_ENCRYPTED_STREAM_NOT_ALLOWED = 2,
   /**
-   * 3: Timeout for the RTMP or RTMPS streaming. Call the `addPublishStreamUrl` method to publish the streaming again.
+   * 3: Timeout for the RTMP or RTMPS streaming. Call the `addPublishStreamUrl` method to publish
+   * the streaming again.
    */
   RTMP_STREAM_PUBLISH_REASON_CONNECTION_TIMEOUT = 3,
   /**
-   * 4: An error occurs in Agora's streaming server. Call the `addPublishStreamUrl` method to publish the streaming again.
+   * 4: An error occurs in Agora's streaming server. Call the `addPublishStreamUrl` method to
+   * publish the streaming again.
    */
   RTMP_STREAM_PUBLISH_REASON_INTERNAL_SERVER_ERROR = 4,
   /**
@@ -3614,17 +3699,23 @@
    */
   RTMP_STREAM_PUBLISH_REASON_STREAM_NOT_FOUND = 9,
   /**
-   * 10: The format of the RTMP or RTMPS streaming URL is not supported. Check whether the URL format is correct.
+   * 10: The format of the RTMP or RTMPS streaming URL is not supported. Check whether the URL
+   * format is correct.
    */
   RTMP_STREAM_PUBLISH_REASON_FORMAT_NOT_SUPPORTED = 10,
   /**
-   * 11: The user role is not host, so the user cannot use the CDN live streaming function. Check your application code logic.
+   * 11: The user role is not host, so the user cannot use the CDN live streaming function. Check
+   * your application code logic.
    */
-  RTMP_STREAM_PUBLISH_REASON_NOT_BROADCASTER = 11,  // Note: match to ERR_PUBLISH_STREAM_NOT_BROADCASTER in AgoraBase.h
+  RTMP_STREAM_PUBLISH_REASON_NOT_BROADCASTER =
+      11,  // Note: match to ERR_PUBLISH_STREAM_NOT_BROADCASTER in AgoraBase.h
   /**
-   * 13: The `updateRtmpTranscoding` or `setLiveTranscoding` method is called to update the transcoding configuration in a scenario where there is streaming without transcoding. Check your application code logic.
+   * 13: The `updateRtmpTranscoding` or `setLiveTranscoding` method is called to update the
+   * transcoding configuration in a scenario where there is streaming without transcoding. Check
+   * your application code logic.
    */
-  RTMP_STREAM_PUBLISH_REASON_TRANSCODING_NO_MIX_STREAM = 13,  // Note: match to ERR_PUBLISH_STREAM_TRANSCODING_NO_MIX_STREAM in AgoraBase.h
+  RTMP_STREAM_PUBLISH_REASON_TRANSCODING_NO_MIX_STREAM =
+      13,  // Note: match to ERR_PUBLISH_STREAM_TRANSCODING_NO_MIX_STREAM in AgoraBase.h
   /**
    * 14: Errors occurred in the host's network.
    */
@@ -3632,11 +3723,13 @@
   /**
    * 15: Your App ID does not have permission to use the CDN live streaming function.
    */
-  RTMP_STREAM_PUBLISH_REASON_INVALID_APPID = 15,  // Note: match to ERR_PUBLISH_STREAM_APPID_INVALID in AgoraBase.h
+  RTMP_STREAM_PUBLISH_REASON_INVALID_APPID =
+      15,  // Note: match to ERR_PUBLISH_STREAM_APPID_INVALID in AgoraBase.h
   /** invalid privilege. */
   RTMP_STREAM_PUBLISH_REASON_INVALID_PRIVILEGE = 16,
   /**
-   * 100: The streaming has been stopped normally. After you call `removePublishStreamUrl` to stop streaming, the SDK returns this value.
+   * 100: The streaming has been stopped normally. After you call `removePublishStreamUrl` to stop
+   * streaming, the SDK returns this value.
    */
   RTMP_STREAM_UNPUBLISH_REASON_OK = 100,
 };
@@ -3644,11 +3737,13 @@
 /** Events during the RTMP or RTMPS streaming. */
 enum RTMP_STREAMING_EVENT {
   /**
-   * 1: An error occurs when you add a background image or a watermark image to the RTMP or RTMPS stream.
+   * 1: An error occurs when you add a background image or a watermark image to the RTMP or RTMPS
+   * stream.
    */
   RTMP_STREAMING_EVENT_FAILED_LOAD_IMAGE = 1,
   /**
-   * 2: The streaming URL is already being used for CDN live streaming. If you want to start new streaming, use a new streaming URL.
+   * 2: The streaming URL is already being used for CDN live streaming. If you want to start new
+   * streaming, use a new streaming URL.
    */
   RTMP_STREAMING_EVENT_URL_ALREADY_IN_USE = 2,
   /**
@@ -3666,15 +3761,18 @@
  */
 typedef struct RtcImage {
   /**
-   *The HTTP/HTTPS URL address of the image in the live video. The maximum length of this parameter is 1024 bytes.
+   *The HTTP/HTTPS URL address of the image in the live video. The maximum length of this parameter
+   *is 1024 bytes.
    */
   const char* url;
   /**
-   * The x coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin).
+   * The x coordinate (pixel) of the image on the video frame (taking the upper left corner of the
+   * video frame as the origin).
    */
   int x;
   /**
-   * The y coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin).
+   * The y coordinate (pixel) of the image on the video frame (taking the upper left corner of the
+   * video frame as the origin).
    */
   int y;
   /**
@@ -3705,18 +3803,21 @@
 /**
  * The configuration for advanced features of the RTMP or RTMPS streaming with transcoding.
  *
- * If you want to enable the advanced features of streaming with transcoding, contact support@agora.io.
+ * If you want to enable the advanced features of streaming with transcoding, contact
+ * support@agora.io.
  */
 struct LiveStreamAdvancedFeature {
   LiveStreamAdvancedFeature() : featureName(OPTIONAL_NULLPTR), opened(false) {}
-  LiveStreamAdvancedFeature(const char* feat_name, bool open) : featureName(feat_name), opened(open) {}
+  LiveStreamAdvancedFeature(const char* feat_name, bool open)
+      : featureName(feat_name), opened(open) {}
   /** The advanced feature for high-quality video with a lower bitrate. */
   // static const char* LBHQ = "lbhq";
   /** The advanced feature for the optimized video encoder. */
   // static const char* VEO = "veo";
 
   /**
-   * The feature names, including LBHQ (high-quality video with a lower bitrate) and VEO (optimized video encoder).
+   * The feature names, including LBHQ (high-quality video with a lower bitrate) and VEO (optimized
+   * video encoder).
    */
   const char* featureName;
 
@@ -3726,15 +3827,15 @@
    * - `false`: (Default) Disable the advanced feature.
    */
   bool opened;
-} ;
+};
 
 /**
  * Connection state types.
  */
-enum CONNECTION_STATE_TYPE
-{
+enum CONNECTION_STATE_TYPE {
   /**
-   * 1: The SDK is disconnected from the Agora edge server. The state indicates the SDK is in one of the following phases:
+   * 1: The SDK is disconnected from the Agora edge server. The state indicates the SDK is in one of
+   * the following phases:
    * - The initial state before calling the `joinChannel` method.
    * - The app calls the `leaveChannel` method.
    */
@@ -3786,11 +3887,15 @@
    */
   uid_t uid;
   /**
-   * The x coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, width], where width is the `width` set in `LiveTranscoding`.
+   * The x coordinate (pixel) of the host's video on the output video frame (taking the upper left
+   * corner of the video frame as the origin). The value range is [0, width], where width is the
+   * `width` set in `LiveTranscoding`.
    */
   int x;
   /**
-   * The y coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, height], where height is the `height` set in `LiveTranscoding`.
+   * The y coordinate (pixel) of the host's video on the output video frame (taking the upper left
+   * corner of the video frame as the origin). The value range is [0, height], where height is the
+   * `height` set in `LiveTranscoding`.
    */
   int y;
   /**
@@ -3816,28 +3921,29 @@
    */
   double alpha;
   /**
-   * The audio channel used by the host's audio in the output audio. The default value is 0, and the value range is [0, 5].
-   * - `0`: (Recommended) The defaut setting, which supports dual channels at most and depends on the upstream of the host.
-   * - `1`: The host's audio uses the FL audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.
-   * - `2`: The host's audio uses the FC audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.
-   * - `3`: The host's audio uses the FR audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.
-   * - `4`: The host's audio uses the BL audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.
-   * - `5`: The host's audio uses the BR audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.
-   * - `0xFF` or a value greater than 5: The host's audio is muted, and the Agora server removes the host's audio.
+   * The audio channel used by the host's audio in the output audio. The default value is 0, and the
+   * value range is [0, 5].
+   * - `0`: (Recommended) The defaut setting, which supports dual channels at most and depends on
+   * the upstream of the host.
+   * - `1`: The host's audio uses the FL audio channel. If the host's upstream uses multiple audio
+   * channels, the Agora server mixes them into mono first.
+   * - `2`: The host's audio uses the FC audio channel. If the host's upstream uses multiple audio
+   * channels, the Agora server mixes them into mono first.
+   * - `3`: The host's audio uses the FR audio channel. If the host's upstream uses multiple audio
+   * channels, the Agora server mixes them into mono first.
+   * - `4`: The host's audio uses the BL audio channel. If the host's upstream uses multiple audio
+   * channels, the Agora server mixes them into mono first.
+   * - `5`: The host's audio uses the BR audio channel. If the host's upstream uses multiple audio
+   * channels, the Agora server mixes them into mono first.
+   * - `0xFF` or a value greater than 5: The host's audio is muted, and the Agora server removes the
+   * host's audio.
    *
    * @note If the value is not `0`, a special player is required.
    */
   int audioChannel;
 
   TranscodingUser()
-      : uid(0),
-        x(0),
-        y(0),
-        width(0),
-        height(0),
-        zOrder(0),
-        alpha(1.0),
-        audioChannel(0) {}
+      : uid(0), x(0), y(0), width(0), height(0), zOrder(0), alpha(1.0), audioChannel(0) {}
 };
 
 /**
@@ -3860,10 +3966,12 @@
   int height;
   /** Bitrate of the CDN live output video stream. The default value is 400 Kbps.
 
-  Set this parameter according to the Video Bitrate Table. If you set a bitrate beyond the proper range, the SDK automatically adapts it to a value within the range.
+  Set this parameter according to the Video Bitrate Table. If you set a bitrate beyond the proper
+  range, the SDK automatically adapts it to a value within the range.
   */
   int videoBitrate;
-  /** Frame rate of the output video stream set for the CDN live streaming. The default value is 15 fps, and the value range is (0,30].
+  /** Frame rate of the output video stream set for the CDN live streaming. The default value is 15
+  fps, and the value range is (0,30].
 
   @note The Agora server adjusts any value over 30 to 30.
   */
@@ -3884,7 +3992,8 @@
   @note If you set this parameter to other values, Agora adjusts it to the default value of 100.
   */
   VIDEO_CODEC_PROFILE_TYPE videoCodecProfile;
-  /** The background color in RGB hex value. Value only. Do not include a preceeding #. For example, 0xFFB6C1 (light pink). The default value is 0x000000 (black).
+  /** The background color in RGB hex value. Value only. Do not include a preceeding #. For example,
+   * 0xFFB6C1 (light pink). The default value is 0x000000 (black).
    */
   unsigned int backgroundColor;
   /** Video codec profile types for Media Push. See VIDEO_CODEC_TYPE_FOR_STREAM. */
@@ -3893,10 +4002,12 @@
    *  The value range is [0, 17].
    */
   unsigned int userCount;
-  /** Manages the user layout configuration in the Media Push. Agora supports a maximum of 17 transcoding users in a Media Push channel. See `TranscodingUser`.
+  /** Manages the user layout configuration in the Media Push. Agora supports a maximum of 17
+   * transcoding users in a Media Push channel. See `TranscodingUser`.
    */
   TranscodingUser* transcodingUsers;
-  /** Reserved property. Extra user-defined information to send SEI for the H.264/H.265 video stream to the CDN live client. Maximum length: 4096 Bytes.
+  /** Reserved property. Extra user-defined information to send SEI for the H.264/H.265 video stream
+   to the CDN live client. Maximum length: 4096 Bytes.
 
    For more information on SEI frame, see [SEI-related questions](https://docs.agora.io/en/faq/sei).
    */
@@ -3907,31 +4018,38 @@
   const char* metadata;
   /** The watermark on the live video. The image format needs to be PNG. See `RtcImage`.
 
-  You can add one watermark, or add multiple watermarks using an array. This parameter is used with `watermarkCount`.
+  You can add one watermark, or add multiple watermarks using an array. This parameter is used with
+  `watermarkCount`.
   */
   RtcImage* watermark;
   /**
-   * The number of watermarks on the live video. The total number of watermarks and background images can range from 0 to 10. This parameter is used with `watermark`.
+   * The number of watermarks on the live video. The total number of watermarks and background
+   * images can range from 0 to 10. This parameter is used with `watermark`.
    */
   unsigned int watermarkCount;
 
-  /** The number of background images on the live video. The image format needs to be PNG. See `RtcImage`.
+  /** The number of background images on the live video. The image format needs to be PNG. See
+   * `RtcImage`.
    *
-   * You can add a background image or use an array to add multiple background images. This parameter is used with `backgroundImageCount`.
+   * You can add a background image or use an array to add multiple background images. This
+   * parameter is used with `backgroundImageCount`.
    */
   RtcImage* backgroundImage;
   /**
-   * The number of background images on the live video. The total number of watermarks and background images can range from 0 to 10. This parameter is used with `backgroundImage`.
+   * The number of background images on the live video. The total number of watermarks and
+   * background images can range from 0 to 10. This parameter is used with `backgroundImage`.
    */
   unsigned int backgroundImageCount;
 
   /** The audio sampling rate (Hz) of the output media stream. See #AUDIO_SAMPLE_RATE_TYPE.
    */
   AUDIO_SAMPLE_RATE_TYPE audioSampleRate;
-  /** Bitrate (Kbps) of the audio output stream for Media Push. The default value is 48, and the highest value is 128.
+  /** Bitrate (Kbps) of the audio output stream for Media Push. The default value is 48, and the
+   * highest value is 128.
    */
   int audioBitrate;
-  /** The number of audio channels for Media Push. Agora recommends choosing 1 (mono), or 2 (stereo) audio channels. Special players are required if you choose 3, 4, or 5.
+  /** The number of audio channels for Media Push. Agora recommends choosing 1 (mono), or 2 (stereo)
+   * audio channels. Special players are required if you choose 3, 4, or 5.
    * - 1: (Default) Mono.
    * - 2: Stereo.
    * - 3: Three audio channels.
@@ -3942,7 +4060,8 @@
   /** Audio codec profile type for Media Push. See #AUDIO_CODEC_PROFILE_TYPE.
    */
   AUDIO_CODEC_PROFILE_TYPE audioCodecProfile;
-  /** Advanced features of the RTMP or RTMPS streaming with transcoding. See LiveStreamAdvancedFeature.
+  /** Advanced features of the RTMP or RTMPS streaming with transcoding. See
+   * LiveStreamAdvancedFeature.
    */
   LiveStreamAdvancedFeature* advancedFeatures;
 
@@ -3985,12 +4104,14 @@
   VIDEO_SOURCE_TYPE sourceType;
   /**
    * The ID of the remote user.
-   * @note Use this parameter only when the source type of the video for the video mixing on the local client is `VIDEO_SOURCE_REMOTE`.
+   * @note Use this parameter only when the source type of the video for the video mixing on the
+   * local client is `VIDEO_SOURCE_REMOTE`.
    */
   uid_t remoteUserUid;
   /**
    * The URL of the image.
-   * @note Use this parameter only when the source type of the video for the video mixing on the local client is `RTC_IMAGE`.
+   * @note Use this parameter only when the source type of the video for the video mixing on the
+   * local client is `RTC_IMAGE`.
    */
   const char* imageUrl;
   /**
@@ -3998,11 +4119,13 @@
    */
   int mediaPlayerId;
   /**
-   * The horizontal displacement of the top-left corner of the video for the video mixing on the client relative to the top-left corner (origin) of the canvas for this video mixing.
+   * The horizontal displacement of the top-left corner of the video for the video mixing on the
+   * client relative to the top-left corner (origin) of the canvas for this video mixing.
    */
   int x;
   /**
-   * The vertical displacement of the top-left corner of the video for the video mixing on the client relative to the top-left corner (origin) of the canvas for this video mixing.
+   * The vertical displacement of the top-left corner of the video for the video mixing on the
+   * client relative to the top-left corner (origin) of the canvas for this video mixing.
    */
   int y;
   /**
@@ -4014,13 +4137,16 @@
    */
   int height;
   /**
-   * The number of the layer to which the video for the video mixing on the local client belongs. The value range is [0,100].
+   * The number of the layer to which the video for the video mixing on the local client belongs.
+   * The value range is [0,100].
    * - 0: (Default) The layer is at the bottom.
    * - 100: The layer is at the top.
    */
   int zOrder;
   /**
-   * The transparency of the video for the video mixing on the local client. The value range is [0.0,1.0]. 0.0 means the transparency is completely transparent. 1.0 means the transparency is opaque.
+   * The transparency of the video for the video mixing on the local client. The value range is
+   * [0.0,1.0]. 0.0 means the transparency is completely transparent. 1.0 means the transparency is
+   * opaque.
    */
   double alpha;
   /**
@@ -4057,17 +4183,25 @@
    */
   TranscodingVideoStream* videoInputStreams;
   /**
-   * The encoding configuration of the mixed video stream after the video mixing on the local client. See VideoEncoderConfiguration.
+   * The encoding configuration of the mixed video stream after the video mixing on the local
+   * client. See VideoEncoderConfiguration.
    */
   VideoEncoderConfiguration videoOutputConfiguration;
   /**
-   * Whether to use the timestamp when the primary camera captures the video frame as the timestamp of the mixed video frame.
-   * - true: (Default) Use the timestamp of the captured video frame as the timestamp of the mixed video frame.
-   * - false: Do not use the timestamp of the captured video frame as the timestamp of the mixed video frame. Instead, use the timestamp when the mixed video frame is constructed.
+   * Whether to use the timestamp when the primary camera captures the video frame as the timestamp
+   * of the mixed video frame.
+   * - true: (Default) Use the timestamp of the captured video frame as the timestamp of the mixed
+   * video frame.
+   * - false: Do not use the timestamp of the captured video frame as the timestamp of the mixed
+   * video frame. Instead, use the timestamp when the mixed video frame is constructed.
    */
   bool syncWithPrimaryCamera;
 
-  LocalTranscoderConfiguration() : streamCount(0), videoInputStreams(OPTIONAL_NULLPTR), videoOutputConfiguration(), syncWithPrimaryCamera(true) {}
+  LocalTranscoderConfiguration()
+      : streamCount(0),
+        videoInputStreams(OPTIONAL_NULLPTR),
+        videoOutputConfiguration(),
+        syncWithPrimaryCamera(true) {}
 };
 
 enum VIDEO_TRANSCODER_ERROR {
@@ -4097,7 +4231,78 @@
   VT_ERR_INTERNAL = 20
 };
 
+
 /**
+ * The audio streams for the video mixing on the local client.
+ */
+struct MixedAudioStream {
+  /**
+   * The source type of audio for the audio mixing on the local client. See #AUDIO_SOURCE_TYPE.
+   */
+  AUDIO_SOURCE_TYPE sourceType;
+  /**
+   * The ID of the remote user.
+   * @note Use this parameter only when the source type is `AUDIO_SOURCE_REMOTE`.
+   */
+  uid_t remoteUserUid;
+  /**
+   * The channel ID of the remote user.
+   * @note Use this parameter only when the source type is `AUDIO_SOURCE_REMOTE`.
+   */
+  const char* channelId;
+  /**
+   * The track ID of the local track.
+   * @note Use this parameter only when the source type is `AUDIO_SOURCE_REMOTE`.
+   */
+  track_id_t trackId;
+
+  MixedAudioStream(AUDIO_SOURCE_TYPE source)
+    : sourceType(source),
+      remoteUserUid(0),
+      channelId(NULL),
+      trackId(-1) {}
+
+  MixedAudioStream(AUDIO_SOURCE_TYPE source, track_id_t track)
+    : sourceType(source),
+      trackId(track) {}
+
+  MixedAudioStream(AUDIO_SOURCE_TYPE source, uid_t uid, const char* channel)
+    : sourceType(source),
+      remoteUserUid(uid),
+      channelId(channel) {}
+
+  MixedAudioStream(AUDIO_SOURCE_TYPE source, uid_t uid, const char* channel, track_id_t track)
+    : sourceType(source),
+      remoteUserUid(uid),
+      channelId(channel),
+      trackId(track) {}
+
+};
+
+/**
+ * The configuration of the audio mixing on the local client.
+ */
+struct LocalAudioMixerConfiguration {
+  /**
+   * The number of the audio streams for the audio mixing on the local client.
+   */
+  unsigned int streamCount;
+  /**
+   * The source of the streams to mixed;
+   */  
+  MixedAudioStream* audioInputStreams;
+
+  /**
+   * Whether to use the timestamp follow the local mic's audio frame.
+   * - true: (Default) Use the timestamp of the captured audio frame as the timestamp of the mixed audio frame.
+   * - false: Do not use the timestamp of the captured audio frame as the timestamp of the mixed audio frame. Instead, use the timestamp when the mixed audio frame is constructed.
+   */
+  bool syncWithLocalMic;
+
+  LocalAudioMixerConfiguration() : streamCount(0), syncWithLocalMic(true) {}
+};
+
+/**
  * Configurations of the last-mile network test.
  */
 struct LastmileProbeConfig {
@@ -4115,12 +4320,14 @@
    */
   bool probeDownlink;
   /**
-   * The expected maximum sending bitrate (bps) of the local user. The value range is [100000, 5000000]. We recommend setting this parameter
-   * according to the bitrate value set by `setVideoEncoderConfiguration`.
+   * The expected maximum sending bitrate (bps) of the local user. The value range is [100000,
+   * 5000000]. We recommend setting this parameter according to the bitrate value set by
+   * `setVideoEncoderConfiguration`.
    */
   unsigned int expectedUplinkBitrate;
   /**
-   * The expected maximum receiving bitrate (bps) of the local user. The value range is [100000,5000000].
+   * The expected maximum receiving bitrate (bps) of the local user. The value range is
+   * [100000,5000000].
    */
   unsigned int expectedDownlinkBitrate;
 };
@@ -4134,11 +4341,13 @@
    */
   LASTMILE_PROBE_RESULT_COMPLETE = 1,
   /**
-   * 2: The last-mile network probe test is incomplete because the bandwidth estimation is not available due to limited test resources.
+   * 2: The last-mile network probe test is incomplete because the bandwidth estimation is not
+   * available due to limited test resources.
    */
   LASTMILE_PROBE_RESULT_INCOMPLETE_NO_BWE = 2,
   /**
-   * 3: The last-mile network probe test is not carried out, probably due to poor network conditions.
+   * 3: The last-mile network probe test is not carried out, probably due to poor network
+   * conditions.
    */
   LASTMILE_PROBE_RESULT_UNAVAILABLE = 3
 };
@@ -4160,9 +4369,7 @@
    */
   unsigned int availableBandwidth;
 
-  LastmileProbeOneWayResult() : packetLossRate(0),
-                                jitter(0),
-                                availableBandwidth(0) {}
+  LastmileProbeOneWayResult() : packetLossRate(0), jitter(0), availableBandwidth(0) {}
 };
 
 /**
@@ -4186,16 +4393,13 @@
    */
   unsigned int rtt;
 
-  LastmileProbeResult()
-    : state(LASTMILE_PROBE_RESULT_UNAVAILABLE),
-      rtt(0) {}
+  LastmileProbeResult() : state(LASTMILE_PROBE_RESULT_UNAVAILABLE), rtt(0) {}
 };
 
 /**
  * Reasons causing the change of the connection state.
  */
-enum CONNECTION_CHANGED_REASON_TYPE
-{
+enum CONNECTION_CHANGED_REASON_TYPE {
   /**
    * 0: The SDK is connecting to the server.
    */
@@ -4209,11 +4413,13 @@
    */
   CONNECTION_CHANGED_INTERRUPTED = 2,
   /**
-   * 3: The connection between the SDK and the server is banned by the server. This error occurs when the user is kicked out of the channel by the server.
+   * 3: The connection between the SDK and the server is banned by the server. This error occurs
+   * when the user is kicked out of the channel by the server.
    */
   CONNECTION_CHANGED_BANNED_BY_SERVER = 3,
   /**
-   * 4: The SDK fails to join the channel. When the SDK fails to join the channel for more than 20 minutes, this error occurs and the SDK stops reconnecting to the channel.
+   * 4: The SDK fails to join the channel. When the SDK fails to join the channel for more than 20
+   * minutes, this error occurs and the SDK stops reconnecting to the channel.
    */
   CONNECTION_CHANGED_JOIN_FAILED = 4,
   /**
@@ -4225,13 +4431,17 @@
    */
   CONNECTION_CHANGED_INVALID_APP_ID = 6,
   /**
-   * 7: The connection fails because the channel name is not valid. Please rejoin the channel with a valid channel name.
+   * 7: The connection fails because the channel name is not valid. Please rejoin the channel with a
+   * valid channel name.
    */
   CONNECTION_CHANGED_INVALID_CHANNEL_NAME = 7,
   /**
    * 8: The connection fails because the token is not valid. Typical reasons include:
-   * - The App Certificate for the project is enabled in Agora Console, but you do not use a token when joining the channel. If you enable the App Certificate, you must use a token to join the channel.
-   * - The `uid` specified when calling `joinChannel` to join the channel is inconsistent with the `uid` passed in when generating the token.
+   * - The App Certificate for the project is enabled in Agora Console, but you do not use a token
+   * when joining the channel. If you enable the App Certificate, you must use a token to join the
+   * channel.
+   * - The `uid` specified when calling `joinChannel` to join the channel is inconsistent with the
+   * `uid` passed in when generating the token.
    */
   CONNECTION_CHANGED_INVALID_TOKEN = 8,
   /**
@@ -4240,8 +4450,10 @@
   CONNECTION_CHANGED_TOKEN_EXPIRED = 9,
   /**
    * 10: The connection is rejected by the server. Typical reasons include:
-   * - The user is already in the channel and still calls a method, for example, `joinChannel`, to join the channel. Stop calling this method to clear this error.
-   * - The user tries to join the channel when conducting a pre-call test. The user needs to call the channel after the call test ends.
+   * - The user is already in the channel and still calls a method, for example, `joinChannel`, to
+   * join the channel. Stop calling this method to clear this error.
+   * - The user tries to join the channel when conducting a pre-call test. The user needs to call
+   * the channel after the call test ends.
    */
   CONNECTION_CHANGED_REJECTED_BY_SERVER = 10,
   /**
@@ -4253,11 +4465,13 @@
    */
   CONNECTION_CHANGED_RENEW_TOKEN = 12,
   /**
-   * 13: The IP address of the client has changed, possibly because the network type, IP address, or port has been changed.
+   * 13: The IP address of the client has changed, possibly because the network type, IP address, or
+   * port has been changed.
    */
   CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED = 13,
   /**
-   * 14: Timeout for the keep-alive of the connection between the SDK and the Agora edge server. The connection state changes to CONNECTION_STATE_RECONNECTING.
+   * 14: Timeout for the keep-alive of the connection between the SDK and the Agora edge server. The
+   * connection state changes to CONNECTION_STATE_RECONNECTING.
    */
   CONNECTION_CHANGED_KEEP_ALIVE_TIMEOUT = 14,
   /**
@@ -4354,11 +4568,13 @@
    */
   WLACC_SUGGEST_ACTION_CONNECT_SSID = 1,
   /**
-   * The user is advised to check whether the AP supports 5G band and enable 5G band (the aciton link is attached), or purchases an AP that supports 5G. AP does not support 5G band.
+   * The user is advised to check whether the AP supports 5G band and enable 5G band (the aciton
+   * link is attached), or purchases an AP that supports 5G. AP does not support 5G band.
    */
   WLACC_SUGGEST_ACTION_CHECK_5G = 2,
   /**
-   * The user is advised to change the SSID of the 2.4G or 5G band (the aciton link is attached). The SSID of the 2.4G band AP is the same as that of the 5G band.
+   * The user is advised to change the SSID of the 2.4G or 5G band (the aciton link is attached).
+   * The SSID of the 2.4G band AP is the same as that of the 5G band.
    */
   WLACC_SUGGEST_ACTION_MODIFY_SSID = 3,
 };
@@ -4447,7 +4663,8 @@
   uid_t uid;
 
   /**
-  * The uid of video stream composing the video stream from transcoder which will be drawn on this video canvas. 
+   * The uid of video stream composing the video stream from transcoder which will be drawn on this
+   * video canvas.
    */
   uid_t subviewUid;
   /**
@@ -4508,24 +4725,61 @@
   media::base::VIDEO_MODULE_POSITION position;
 
   VideoCanvas()
-    : uid(0), subviewUid(0), view(NULL), backgroundColor(0x00000000), renderMode(media::base::RENDER_MODE_HIDDEN), mirrorMode(VIDEO_MIRROR_MODE_AUTO),
-      setupMode(VIDEO_VIEW_SETUP_REPLACE), sourceType(VIDEO_SOURCE_CAMERA_PRIMARY), mediaPlayerId(-ERR_NOT_READY),
-      cropArea(0, 0, 0, 0), enableAlphaMask(false), position(media::base::POSITION_POST_CAPTURER) {}
+      : uid(0),
+        subviewUid(0),
+        view(NULL),
+        backgroundColor(0x00000000),
+        renderMode(media::base::RENDER_MODE_HIDDEN),
+        mirrorMode(VIDEO_MIRROR_MODE_AUTO),
+        setupMode(VIDEO_VIEW_SETUP_REPLACE),
+        sourceType(VIDEO_SOURCE_CAMERA_PRIMARY),
+        mediaPlayerId(-ERR_NOT_READY),
+        cropArea(0, 0, 0, 0),
+        enableAlphaMask(false),
+        position(media::base::POSITION_POST_CAPTURER) {}
 
   VideoCanvas(view_t v, media::base::RENDER_MODE_TYPE m, VIDEO_MIRROR_MODE_TYPE mt)
-    : uid(0), subviewUid(0), view(v), backgroundColor(0x00000000), renderMode(m), mirrorMode(mt), setupMode(VIDEO_VIEW_SETUP_REPLACE),
-      sourceType(VIDEO_SOURCE_CAMERA_PRIMARY), mediaPlayerId(-ERR_NOT_READY),
-      cropArea(0, 0, 0, 0), enableAlphaMask(false), position(media::base::POSITION_POST_CAPTURER) {}
+      : uid(0),
+        subviewUid(0),
+        view(v),
+        backgroundColor(0x00000000),
+        renderMode(m),
+        mirrorMode(mt),
+        setupMode(VIDEO_VIEW_SETUP_REPLACE),
+        sourceType(VIDEO_SOURCE_CAMERA_PRIMARY),
+        mediaPlayerId(-ERR_NOT_READY),
+        cropArea(0, 0, 0, 0),
+        enableAlphaMask(false),
+        position(media::base::POSITION_POST_CAPTURER) {}
 
   VideoCanvas(view_t v, media::base::RENDER_MODE_TYPE m, VIDEO_MIRROR_MODE_TYPE mt, uid_t u)
-    : uid(u), subviewUid(0), view(v), backgroundColor(0x00000000), renderMode(m), mirrorMode(mt), setupMode(VIDEO_VIEW_SETUP_REPLACE),
-      sourceType(VIDEO_SOURCE_CAMERA_PRIMARY), mediaPlayerId(-ERR_NOT_READY),
-      cropArea(0, 0, 0, 0), enableAlphaMask(false), position(media::base::POSITION_POST_CAPTURER) {}
+      : uid(u),
+        subviewUid(0),
+        view(v),
+        backgroundColor(0x00000000),
+        renderMode(m),
+        mirrorMode(mt),
+        setupMode(VIDEO_VIEW_SETUP_REPLACE),
+        sourceType(VIDEO_SOURCE_CAMERA_PRIMARY),
+        mediaPlayerId(-ERR_NOT_READY),
+        cropArea(0, 0, 0, 0),
+        enableAlphaMask(false),
+        position(media::base::POSITION_POST_CAPTURER) {}
 
-  VideoCanvas(view_t v, media::base::RENDER_MODE_TYPE m, VIDEO_MIRROR_MODE_TYPE mt, uid_t u, uid_t subu)
-    : uid(u), subviewUid(subu), view(v), backgroundColor(0x00000000), renderMode(m), mirrorMode(mt), setupMode(VIDEO_VIEW_SETUP_REPLACE),
-      sourceType(VIDEO_SOURCE_CAMERA_PRIMARY), mediaPlayerId(-ERR_NOT_READY),
-      cropArea(0, 0, 0, 0), enableAlphaMask(false), position(media::base::POSITION_POST_CAPTURER) {}
+  VideoCanvas(view_t v, media::base::RENDER_MODE_TYPE m, VIDEO_MIRROR_MODE_TYPE mt, uid_t u,
+              uid_t subu)
+      : uid(u),
+        subviewUid(subu),
+        view(v),
+        backgroundColor(0x00000000),
+        renderMode(m),
+        mirrorMode(mt),
+        setupMode(VIDEO_VIEW_SETUP_REPLACE),
+        sourceType(VIDEO_SOURCE_CAMERA_PRIMARY),
+        mediaPlayerId(-ERR_NOT_READY),
+        cropArea(0, 0, 0, 0),
+        enableAlphaMask(false),
+        position(media::base::POSITION_POST_CAPTURER) {}
 };
 
 /** Image enhancement options.
@@ -4542,28 +4796,44 @@
       LIGHTENING_CONTRAST_HIGH = 2,
   };
 
-  /** The contrast level, used with the `lighteningLevel` parameter. The larger the value, the greater the contrast between light and dark. See #LIGHTENING_CONTRAST_LEVEL.
+  /** The contrast level, used with the `lighteningLevel` parameter. The larger the value, the
+   * greater the contrast between light and dark. See #LIGHTENING_CONTRAST_LEVEL.
     */
   LIGHTENING_CONTRAST_LEVEL lighteningContrastLevel;
 
-  /** The brightness level. The value ranges from 0.0 (original) to 1.0. The default value is 0.0. The greater the value, the greater the degree of whitening. */
+  /** The brightness level. The value ranges from 0.0 (original) to 1.0. The default value is 0.0.
+   * The greater the value, the greater the degree of whitening. */
   float lighteningLevel;
 
-  /** The value ranges from 0.0 (original) to 1.0. The default value is 0.0. The greater the value, the greater the degree of skin grinding.
+  /** The value ranges from 0.0 (original) to 1.0. The default value is 0.0. The greater the value,
+   * the greater the degree of skin grinding.
     */
   float smoothnessLevel;
 
-  /** The redness level. The value ranges from 0.0 (original) to 1.0. The default value is 0.0. The larger the value, the greater the rosy degree.
+  /** The redness level. The value ranges from 0.0 (original) to 1.0. The default value is 0.0. The
+   * larger the value, the greater the rosy degree.
     */
   float rednessLevel;
 
-  /** The sharpness level. The value ranges from 0.0 (original) to 1.0. The default value is 0.0. The larger the value, the greater the sharpening degree.
+  /** The sharpness level. The value ranges from 0.0 (original) to 1.0. The default value is 0.0.
+   * The larger the value, the greater the sharpening degree.
   */
   float sharpnessLevel;
 
-  BeautyOptions(LIGHTENING_CONTRAST_LEVEL contrastLevel, float lightening, float smoothness, float redness, float sharpness) : lighteningContrastLevel(contrastLevel), lighteningLevel(lightening), smoothnessLevel(smoothness), rednessLevel(redness), sharpnessLevel(sharpness) {}
+  BeautyOptions(LIGHTENING_CONTRAST_LEVEL contrastLevel, float lightening, float smoothness,
+                float redness, float sharpness)
+      : lighteningContrastLevel(contrastLevel),
+        lighteningLevel(lightening),
+        smoothnessLevel(smoothness),
+        rednessLevel(redness),
+        sharpnessLevel(sharpness) {}
 
-  BeautyOptions() : lighteningContrastLevel(LIGHTENING_CONTRAST_NORMAL), lighteningLevel(0), smoothnessLevel(0), rednessLevel(0), sharpnessLevel(0) {}
+  BeautyOptions()
+      : lighteningContrastLevel(LIGHTENING_CONTRAST_NORMAL),
+        lighteningLevel(0),
+        smoothnessLevel(0),
+        rednessLevel(0),
+        sharpnessLevel(0) {}
 };
 
 /** Face shape area options. This structure defines options for facial adjustments on different facial areas.
@@ -4645,12 +4915,45 @@
   FaceShapeBeautyOptions() : shapeStyle(FACE_SHAPE_BEAUTY_STYLE_FEMALE), styleIntensity(50) {}
 };
 
+/** Filter effect options. This structure defines options for filter effect.
+ *
+ * @since v4.4.1
+ */
+struct FilterEffectOptions {
+  /**
+   * The local absolute path of the custom 3D Cube path. Only cube format is supported.
+   * The cube file must strictly comply with the Cube LUT Specification; otherwise, the filter effects will not take effect.
+   *
+   * The following is an example of the Cube file format. The cube file starts with `LUT_3D_SIZE`, which indicates the cube size. In filter effects, the cube size is limited to 32.
+
+   * LUT_3D_SIZE 32
+   * 0.0039215689 0 0.0039215682
+   * 0.0086021447 0.0037950677 0
+   * 0.0728652592 0.0039215689 0
+   * ...
+   *
+   * The SDK provides a built-in cube named `built_in_whiten.cube` for whitening. To use this cube, specify the path to `built_in_whiten_filter`
+   */
+  const char * path;
+  
+  /**
+   * The intensity of specified filter effect. The value ranges from 0.0 to 1.0. The default value is 0.5. The greater the value, the stronger the intensity of the filter.
+   */
+  float strength;
+  
+  FilterEffectOptions(const char * lut3dPath, float filterStrength) : path(lut3dPath), strength(filterStrength) {}
+
+  FilterEffectOptions() : path(OPTIONAL_NULLPTR), strength(0.5) {}
+};
+
 struct LowlightEnhanceOptions {
   /**
    * The low-light enhancement mode.
    */
   enum LOW_LIGHT_ENHANCE_MODE {
-    /** 0: (Default) Automatic mode. The SDK automatically enables or disables the low-light enhancement feature according to the ambient light to compensate for the lighting level or prevent overexposure, as necessary. */
+    /** 0: (Default) Automatic mode. The SDK automatically enables or disables the low-light
+       enhancement feature according to the ambient light to compensate for the lighting level or
+       prevent overexposure, as necessary. */
     LOW_LIGHT_ENHANCE_AUTO = 0,
     /** Manual mode. Users need to enable or disable the low-light enhancement feature manually. */
     LOW_LIGHT_ENHANCE_MANUAL = 1,
@@ -4660,11 +4963,14 @@
    */
   enum LOW_LIGHT_ENHANCE_LEVEL {
     /**
-     * 0: (Default) Promotes video quality during low-light enhancement. It processes the brightness, details, and noise of the video image. The performance consumption is moderate, the processing speed is moderate, and the overall video quality is optimal.
+     * 0: (Default) Promotes video quality during low-light enhancement. It processes the
+     * brightness, details, and noise of the video image. The performance consumption is moderate,
+     * the processing speed is moderate, and the overall video quality is optimal.
      */
     LOW_LIGHT_ENHANCE_LEVEL_HIGH_QUALITY = 0,
     /**
-     * Promotes performance during low-light enhancement. It processes the brightness and details of the video image. The processing speed is faster.
+     * Promotes performance during low-light enhancement. It processes the brightness and details of
+     * the video image. The processing speed is faster.
      */
     LOW_LIGHT_ENHANCE_LEVEL_FAST = 1,
   };
@@ -4677,9 +4983,11 @@
    */
   LOW_LIGHT_ENHANCE_LEVEL level;
 
-  LowlightEnhanceOptions(LOW_LIGHT_ENHANCE_MODE lowlightMode, LOW_LIGHT_ENHANCE_LEVEL lowlightLevel) : mode(lowlightMode), level(lowlightLevel) {}
+  LowlightEnhanceOptions(LOW_LIGHT_ENHANCE_MODE lowlightMode, LOW_LIGHT_ENHANCE_LEVEL lowlightLevel)
+      : mode(lowlightMode), level(lowlightLevel) {}
 
-  LowlightEnhanceOptions() : mode(LOW_LIGHT_ENHANCE_AUTO), level(LOW_LIGHT_ENHANCE_LEVEL_HIGH_QUALITY) {}
+  LowlightEnhanceOptions()
+      : mode(LOW_LIGHT_ENHANCE_AUTO), level(LOW_LIGHT_ENHANCE_LEVEL_HIGH_QUALITY) {}
 };
 /**
  * The video noise reduction options.
@@ -4690,7 +4998,8 @@
   /** The video noise reduction mode.
    */
   enum VIDEO_DENOISER_MODE {
-    /** 0: (Default) Automatic mode. The SDK automatically enables or disables the video noise reduction feature according to the ambient light. */
+    /** 0: (Default) Automatic mode. The SDK automatically enables or disables the video noise
+       reduction feature according to the ambient light. */
     VIDEO_DENOISER_AUTO = 0,
     /** Manual mode. Users need to enable or disable the video noise reduction feature manually. */
     VIDEO_DENOISER_MANUAL = 1,
@@ -4700,21 +5009,20 @@
    */
   enum VIDEO_DENOISER_LEVEL {
     /**
-     * 0: (Default) Promotes video quality during video noise reduction. `HIGH_QUALITY` balances performance consumption and video noise reduction quality.
-     * The performance consumption is moderate, the video noise reduction speed is moderate, and the overall video quality is optimal.
+     * 0: (Default) Promotes video quality during video noise reduction. `HIGH_QUALITY` balances
+     * performance consumption and video noise reduction quality. The performance consumption is
+     * moderate, the video noise reduction speed is moderate, and the overall video quality is
+     * optimal.
      */
     VIDEO_DENOISER_LEVEL_HIGH_QUALITY = 0,
     /**
-     * Promotes reducing performance consumption during video noise reduction. `FAST` prioritizes reducing performance consumption over video noise reduction quality.
-     * The performance consumption is lower, and the video noise reduction speed is faster. To avoid a noticeable shadowing effect (shadows trailing behind moving objects) in the processed video, Agora recommends that you use `FAST` when the camera is fixed.
+     * Promotes reducing performance consumption during video noise reduction. `FAST` prioritizes
+     * reducing performance consumption over video noise reduction quality. The performance
+     * consumption is lower, and the video noise reduction speed is faster. To avoid a noticeable
+     * shadowing effect (shadows trailing behind moving objects) in the processed video, Agora
+     * recommends that you use `FAST` when the camera is fixed.
      */
     VIDEO_DENOISER_LEVEL_FAST = 1,
-    /**
-     * Enhanced video noise reduction. `STRENGTH` prioritizes video noise reduction quality over reducing performance consumption.
-     * The performance consumption is higher, the video noise reduction speed is slower, and the video noise reduction quality is better.
-     * If `HIGH_QUALITY` is not enough for your video noise reduction needs, you can use `STRENGTH`.
-     */
-    VIDEO_DENOISER_LEVEL_STRENGTH = 2,
   };
   /** The video noise reduction mode. See #VIDEO_DENOISER_MODE.
    */
@@ -4724,7 +5032,8 @@
    */
   VIDEO_DENOISER_LEVEL level;
 
-  VideoDenoiserOptions(VIDEO_DENOISER_MODE denoiserMode, VIDEO_DENOISER_LEVEL denoiserLevel) : mode(denoiserMode), level(denoiserLevel) {}
+  VideoDenoiserOptions(VIDEO_DENOISER_MODE denoiserMode, VIDEO_DENOISER_LEVEL denoiserLevel)
+      : mode(denoiserMode), level(denoiserLevel) {}
 
   VideoDenoiserOptions() : mode(VIDEO_DENOISER_AUTO), level(VIDEO_DENOISER_LEVEL_HIGH_QUALITY) {}
 };
@@ -4734,17 +5043,24 @@
  * @since v4.0.0
  */
 struct ColorEnhanceOptions {
-  /** The level of color enhancement. The value range is [0.0,1.0]. `0.0` is the default value, which means no color enhancement is applied to the video. The higher the value, the higher the level of color enhancement.
+  /** The level of color enhancement. The value range is [0.0,1.0]. `0.0` is the default value,
+   * which means no color enhancement is applied to the video. The higher the value, the higher the
+   * level of color enhancement.
    */
   float strengthLevel;
 
-  /** The level of skin tone protection. The value range is [0.0,1.0]. `0.0` means no skin tone protection. The higher the value, the higher the level of skin tone protection.
-   * The default value is `1.0`. When the level of color enhancement is higher, the portrait skin tone can be significantly distorted, so you need to set the level of skin tone protection; when the level of skin tone protection is higher, the color enhancement effect can be slightly reduced.
-   * Therefore, to get the best color enhancement effect, Agora recommends that you adjust `strengthLevel` and `skinProtectLevel` to get the most appropriate values.
+  /** The level of skin tone protection. The value range is [0.0,1.0]. `0.0` means no skin tone
+   * protection. The higher the value, the higher the level of skin tone protection. The default
+   * value is `1.0`. When the level of color enhancement is higher, the portrait skin tone can be
+   * significantly distorted, so you need to set the level of skin tone protection; when the level
+   * of skin tone protection is higher, the color enhancement effect can be slightly reduced.
+   * Therefore, to get the best color enhancement effect, Agora recommends that you adjust
+   * `strengthLevel` and `skinProtectLevel` to get the most appropriate values.
    */
   float skinProtectLevel;
 
-  ColorEnhanceOptions(float stength, float skinProtect) : strengthLevel(stength), skinProtectLevel(skinProtect) {}
+  ColorEnhanceOptions(float stength, float skinProtect)
+      : strengthLevel(stength), skinProtectLevel(skinProtect) {}
 
   ColorEnhanceOptions() : strengthLevel(0), skinProtectLevel(1) {}
 };
@@ -4781,11 +5097,14 @@
   /** The degree of blurring applied to the background source.
    */
   enum BACKGROUND_BLUR_DEGREE {
-    /** 1: The degree of blurring applied to the custom background image is low. The user can almost see the background clearly. */
+    /** 1: The degree of blurring applied to the custom background image is low. The user can almost
+       see the background clearly. */
     BLUR_DEGREE_LOW = 1,
-    /** 2: The degree of blurring applied to the custom background image is medium. It is difficult for the user to recognize details in the background. */
+    /** 2: The degree of blurring applied to the custom background image is medium. It is difficult
+       for the user to recognize details in the background. */
     BLUR_DEGREE_MEDIUM = 2,
-    /** 3: (Default) The degree of blurring applied to the custom background image is high. The user can barely see any distinguishing features in the background. */
+    /** 3: (Default) The degree of blurring applied to the custom background image is high. The user
+       can barely see any distinguishing features in the background. */
     BLUR_DEGREE_HIGH = 3,
   };
 
@@ -4794,33 +5113,40 @@
   BACKGROUND_SOURCE_TYPE background_source_type;
 
   /**
-   * The color of the custom background image. The format is a hexadecimal integer defined by RGB, without the # sign,
-   * such as 0xFFB6C1 for light pink. The default value is 0xFFFFFF, which signifies white. The value range
-   * is [0x000000,0xFFFFFF]. If the value is invalid, the SDK replaces the original background image with a white
-   * background image.
+   * The color of the custom background image. The format is a hexadecimal integer defined by RGB,
+   * without the # sign, such as 0xFFB6C1 for light pink. The default value is 0xFFFFFF, which
+   * signifies white. The value range is [0x000000,0xFFFFFF]. If the value is invalid, the SDK
+   * replaces the original background image with a white background image.
    *
-   * @note This parameter takes effect only when the type of the custom background image is `BACKGROUND_COLOR`.
+   * @note This parameter takes effect only when the type of the custom background image is
+   * `BACKGROUND_COLOR`.
    */
   unsigned int color;
 
   /**
-   * The local absolute path of the custom background image. PNG and JPG formats are supported. If the path is invalid,
-   * the SDK replaces the original background image with a white background image.
+   * The local absolute path of the custom background image. PNG and JPG formats are supported. If
+   * the path is invalid, the SDK replaces the original background image with a white background
+   * image.
    *
-   * @note This parameter takes effect only when the type of the custom background image is `BACKGROUND_IMG`.
+   * @note This parameter takes effect only when the type of the custom background image is
+   * `BACKGROUND_IMG`.
    */
   const char* source;
 
   /** The degree of blurring applied to the custom background image. See BACKGROUND_BLUR_DEGREE.
-   * @note This parameter takes effect only when the type of the custom background image is `BACKGROUND_BLUR`.
+   * @note This parameter takes effect only when the type of the custom background image is
+   * `BACKGROUND_BLUR`.
    */
   BACKGROUND_BLUR_DEGREE blur_degree;
 
-  VirtualBackgroundSource() : background_source_type(BACKGROUND_COLOR), color(0xffffff), source(OPTIONAL_NULLPTR),  blur_degree(BLUR_DEGREE_HIGH) {}
+  VirtualBackgroundSource()
+      : background_source_type(BACKGROUND_COLOR),
+        color(0xffffff),
+        source(OPTIONAL_NULLPTR),
+        blur_degree(BLUR_DEGREE_HIGH) {}
 };
 
 struct SegmentationProperty {
-
   enum SEG_MODEL_TYPE {
 
     SEG_MODEL_AI = 1,
@@ -4831,12 +5157,11 @@
 
   float greenCapacity;
 
-
-  SegmentationProperty() : modelType(SEG_MODEL_AI), greenCapacity(0.5){}
+  SegmentationProperty() : modelType(SEG_MODEL_AI), greenCapacity(0.5) {}
 };
 
 /** The type of custom audio track
-*/
+ */
 enum AUDIO_TRACK_TYPE {
   /**
    * -1: Invalid audio track
@@ -4851,14 +5176,14 @@
   AUDIO_TRACK_MIXABLE = 0,
   /**
    * 1: Direct audio track
-   * You can only push one direct (non-mixable) audio track into one RTC connection(channel id + uid). 
-   * Compare to mixable stream, you can have lower lantency using direct audio track.
+   * You can only push one direct (non-mixable) audio track into one RTC connection(channel id +
+   * uid). Compare to mixable stream, you can have lower lantency using direct audio track.
    */
   AUDIO_TRACK_DIRECT = 1,
 };
 
 /** The configuration of custom audio track
-*/
+ */
 struct AudioTrackConfig {
   /**
    * Enable local playback, enabled by default
@@ -4866,9 +5191,14 @@
    * false: Do not enable local playback
    */
   bool enableLocalPlayback;
+  /**
+   * Whether to enable APM (AEC/ANS/AGC) processing when the trackType is AUDIO_TRACK_DIRECT.
+   * false: (Default) Do not enable APM processing.
+   * true: Enable APM processing.
+   */
+  bool enableAudioProcessing;
 
-  AudioTrackConfig()
-    : enableLocalPlayback(true) {}
+  AudioTrackConfig() : enableLocalPlayback(true),enableAudioProcessing(false) {}
 };
 
 /**
@@ -4915,11 +5245,12 @@
   CHAT_BEAUTIFIER_VITALITY = 0x01010300,
   /**
    * Singing beautifier effect.
-   * - If you call `setVoiceBeautifierPreset`(SINGING_BEAUTIFIER), you can beautify a male-sounding voice and add a reverberation effect
-   * that sounds like singing in a small room. Agora recommends not using `setVoiceBeautifierPreset`(SINGING_BEAUTIFIER) to process
-   * a female-sounding voice; otherwise, you may experience vocal distortion.
-   * - If you call `setVoiceBeautifierParameters`(SINGING_BEAUTIFIER, param1, param2), you can beautify a male- or
-   * female-sounding voice and add a reverberation effect.
+   * - If you call `setVoiceBeautifierPreset`(SINGING_BEAUTIFIER), you can beautify a male-sounding
+   * voice and add a reverberation effect that sounds like singing in a small room. Agora recommends
+   * not using `setVoiceBeautifierPreset`(SINGING_BEAUTIFIER) to process a female-sounding voice;
+   * otherwise, you may experience vocal distortion.
+   * - If you call `setVoiceBeautifierParameters`(SINGING_BEAUTIFIER, param1, param2), you can
+   * beautify a male- or female-sounding voice and add a reverberation effect.
    */
   SINGING_BEAUTIFIER = 0x01020100,
   /** A more vigorous voice.
@@ -4949,8 +5280,9 @@
   /**
    * A ultra-high quality voice, which makes the audio clearer and restores more details.
    * - To achieve better audio effect quality, Agora recommends that you call `setAudioProfile`
-   * and set the `profile` to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)`
-   * and `scenario` to `AUDIO_SCENARIO_HIGH_DEFINITION(6)` before calling `setVoiceBeautifierPreset`.
+   * and set the `profile` to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4)` or
+   * `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5)` and `scenario` to
+   * `AUDIO_SCENARIO_HIGH_DEFINITION(6)` before calling `setVoiceBeautifierPreset`.
    * - If you have an audio capturing device that can already restore audio details to a high
    * degree, Agora recommends that you do not enable ultra-high quality; otherwise, the SDK may
    * over-restore audio details, and you may not hear the anticipated voice effect.
@@ -4960,7 +5292,9 @@
 
 /** Preset voice effects.
  *
- * For better voice effects, Agora recommends setting the `profile` parameter of `setAudioProfile` to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO` before using the following presets:
+ * For better voice effects, Agora recommends setting the `profile` parameter of `setAudioProfile`
+ * to `AUDIO_PROFILE_MUSIC_HIGH_QUALITY` or `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO` before using
+ * the following presets:
  *
  * - `ROOM_ACOUSTICS_KTV`
  * - `ROOM_ACOUSTICS_VOCAL_CONCERT`
@@ -5008,8 +5342,8 @@
    */
   ROOM_ACOUSTICS_ETHEREAL = 0x02010700,
   /** A 3D voice effect that makes the voice appear to be moving around the user. The default cycle
-   * period of the 3D voice effect is 10 seconds. To change the cycle period, call `setAudioEffectParameters`
-   * after this method.
+   * period of the 3D voice effect is 10 seconds. To change the cycle period, call
+   * `setAudioEffectParameters` after this method.
    *
    * @note
    * - Before using this preset, set the `profile` parameter of `setAudioProfile` to
@@ -5047,14 +5381,14 @@
   VOICE_CHANGER_EFFECT_UNCLE = 0x02020100,
   /** A senior man's voice.
    *
-   * @note Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may
-   * not hear the anticipated voice effect.
+   * @note Agora recommends using this enumerator to process a male-sounding voice; otherwise, you
+   * may not hear the anticipated voice effect.
    */
   VOICE_CHANGER_EFFECT_OLDMAN = 0x02020200,
   /** A boy's voice.
    *
-   * @note Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may
-   * not hear the anticipated voice effect.
+   * @note Agora recommends using this enumerator to process a male-sounding voice; otherwise, you
+   * may not hear the anticipated voice effect.
    */
   VOICE_CHANGER_EFFECT_BOY = 0x02020300,
   /** A young woman's voice.
@@ -5066,8 +5400,8 @@
   VOICE_CHANGER_EFFECT_SISTER = 0x02020400,
   /** A girl's voice.
    *
-   * @note Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may
-   * not hear the anticipated voice effect.
+   * @note Agora recommends using this enumerator to process a female-sounding voice; otherwise, you
+   * may not hear the anticipated voice effect.
    */
   VOICE_CHANGER_EFFECT_GIRL = 0x02020500,
   /** The voice of Pig King, a character in Journey to the West who has a voice like a growling
@@ -5108,16 +5442,20 @@
   /** Turn off voice conversion and use the original voice.
    */
   VOICE_CONVERSION_OFF = 0x00000000,
-  /** A gender-neutral voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice.
+  /** A gender-neutral voice. To avoid audio distortion, ensure that you use this enumerator to
+   * process a female-sounding voice.
    */
   VOICE_CHANGER_NEUTRAL = 0x03010100,
-  /** A sweet voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice.
+  /** A sweet voice. To avoid audio distortion, ensure that you use this enumerator to process a
+   * female-sounding voice.
    */
   VOICE_CHANGER_SWEET = 0x03010200,
-  /** A steady voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice.
+  /** A steady voice. To avoid audio distortion, ensure that you use this enumerator to process a
+   * male-sounding voice.
    */
   VOICE_CHANGER_SOLID = 0x03010300,
-  /** A deep voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice.
+  /** A deep voice. To avoid audio distortion, ensure that you use this enumerator to process a
+   * male-sounding voice.
    */
   VOICE_CHANGER_BASS = 0x03010400,
   /** A voice like a cartoon character.
@@ -5224,9 +5562,9 @@
    */
   VideoDimensions dimensions;
   /**
-   * On Windows and macOS, it represents the video encoding frame rate (fps) of the shared screen stream.
-   * The frame rate (fps) of the shared region. The default value is 5. We do not recommend setting
-   * this to a value greater than 15.
+   * On Windows and macOS, it represents the video encoding frame rate (fps) of the shared screen
+   * stream. The frame rate (fps) of the shared region. The default value is 5. We do not recommend
+   * setting this to a value greater than 15.
    */
   int frameRate;
   /**
@@ -5241,18 +5579,19 @@
    */
   bool captureMouseCursor;
   /**
-   * Whether to bring the window to the front when calling the `startScreenCaptureByWindowId` method to share it:
+   * Whether to bring the window to the front when calling the `startScreenCaptureByWindowId` method
+   * to share it:
    * - `true`: Bring the window to the front.
    * - `false`: (Default) Do not bring the window to the front.
   */
   bool windowFocus;
   /**
-   * A list of IDs of windows to be blocked. When calling `startScreenCaptureByDisplayId` to start screen sharing,
-   * you can use this parameter to block a specified window. When calling `updateScreenCaptureParameters` to update
-   * screen sharing configurations, you can use this parameter to dynamically block the specified windows during
-   * screen sharing.
+   * A list of IDs of windows to be blocked. When calling `startScreenCaptureByDisplayId` to start
+   * screen sharing, you can use this parameter to block a specified window. When calling
+   * `updateScreenCaptureParameters` to update screen sharing configurations, you can use this
+   * parameter to dynamically block the specified windows during screen sharing.
    */
-  view_t *excludeWindowList;
+  view_t* excludeWindowList;
   /**
    * The number of windows to be blocked.
    */
@@ -5270,23 +5609,79 @@
     * - true: Place a border.
     * - false: (Default) Do not place a border.
     *
-    * @note When you share a part of a window or screen, the SDK places a border around the entire window or screen if you set `enableHighLight` as true.
+   * @note When you share a part of a window or screen, the SDK places a border around the entire
+   * window or screen if you set `enableHighLight` as true.
     *
     */
   bool enableHighLight;
 
   ScreenCaptureParameters()
-    : dimensions(1920, 1080), frameRate(5), bitrate(STANDARD_BITRATE), captureMouseCursor(true), windowFocus(false), excludeWindowList(OPTIONAL_NULLPTR), excludeWindowCount(0), highLightWidth(0), highLightColor(0), enableHighLight(false)  {}
+      : dimensions(1920, 1080),
+        frameRate(5),
+        bitrate(STANDARD_BITRATE),
+        captureMouseCursor(true),
+        windowFocus(false),
+        excludeWindowList(OPTIONAL_NULLPTR),
+        excludeWindowCount(0),
+        highLightWidth(0),
+        highLightColor(0),
+        enableHighLight(false) {}
   ScreenCaptureParameters(const VideoDimensions& d, int f, int b)
-    : dimensions(d), frameRate(f), bitrate(b), captureMouseCursor(true), windowFocus(false), excludeWindowList(OPTIONAL_NULLPTR), excludeWindowCount(0), highLightWidth(0), highLightColor(0), enableHighLight(false) {}
+      : dimensions(d),
+        frameRate(f),
+        bitrate(b),
+        captureMouseCursor(true),
+        windowFocus(false),
+        excludeWindowList(OPTIONAL_NULLPTR),
+        excludeWindowCount(0),
+        highLightWidth(0),
+        highLightColor(0),
+        enableHighLight(false) {}
   ScreenCaptureParameters(int width, int height, int f, int b)
-    : dimensions(width, height), frameRate(f), bitrate(b), captureMouseCursor(true), windowFocus(false), excludeWindowList(OPTIONAL_NULLPTR), excludeWindowCount(0), highLightWidth(0), highLightColor(0), enableHighLight(false){}
+      : dimensions(width, height),
+        frameRate(f),
+        bitrate(b),
+        captureMouseCursor(true),
+        windowFocus(false),
+        excludeWindowList(OPTIONAL_NULLPTR),
+        excludeWindowCount(0),
+        highLightWidth(0),
+        highLightColor(0),
+        enableHighLight(false) {}
   ScreenCaptureParameters(int width, int height, int f, int b, bool cur, bool fcs)
-    : dimensions(width, height), frameRate(f), bitrate(b), captureMouseCursor(cur), windowFocus(fcs), excludeWindowList(OPTIONAL_NULLPTR), excludeWindowCount(0), highLightWidth(0), highLightColor(0), enableHighLight(false) {}
-  ScreenCaptureParameters(int width, int height, int f, int b, view_t *ex, int cnt)
-    : dimensions(width, height), frameRate(f), bitrate(b), captureMouseCursor(true), windowFocus(false), excludeWindowList(ex), excludeWindowCount(cnt), highLightWidth(0), highLightColor(0), enableHighLight(false) {}
-  ScreenCaptureParameters(int width, int height, int f, int b, bool cur, bool fcs, view_t *ex, int cnt)
-    : dimensions(width, height), frameRate(f), bitrate(b), captureMouseCursor(cur), windowFocus(fcs), excludeWindowList(ex), excludeWindowCount(cnt), highLightWidth(0), highLightColor(0), enableHighLight(false) {}
+      : dimensions(width, height),
+        frameRate(f),
+        bitrate(b),
+        captureMouseCursor(cur),
+        windowFocus(fcs),
+        excludeWindowList(OPTIONAL_NULLPTR),
+        excludeWindowCount(0),
+        highLightWidth(0),
+        highLightColor(0),
+        enableHighLight(false) {}
+  ScreenCaptureParameters(int width, int height, int f, int b, view_t* ex, int cnt)
+      : dimensions(width, height),
+        frameRate(f),
+        bitrate(b),
+        captureMouseCursor(true),
+        windowFocus(false),
+        excludeWindowList(ex),
+        excludeWindowCount(cnt),
+        highLightWidth(0),
+        highLightColor(0),
+        enableHighLight(false) {}
+  ScreenCaptureParameters(int width, int height, int f, int b, bool cur, bool fcs, view_t* ex,
+                          int cnt)
+      : dimensions(width, height),
+        frameRate(f),
+        bitrate(b),
+        captureMouseCursor(cur),
+        windowFocus(fcs),
+        excludeWindowList(ex),
+        excludeWindowCount(cnt),
+        highLightWidth(0),
+        highLightColor(0),
+        enableHighLight(false) {}
 };
 
 /**
@@ -5294,15 +5689,18 @@
  */
 enum AUDIO_RECORDING_QUALITY_TYPE {
   /**
-   * 0: Low quality. The sample rate is 32 kHz, and the file size is around 1.2 MB after 10 minutes of recording.
+   * 0: Low quality. The sample rate is 32 kHz, and the file size is around 1.2 MB after 10 minutes
+   * of recording.
    */
   AUDIO_RECORDING_QUALITY_LOW = 0,
   /**
-   * 1: Medium quality. The sample rate is 32 kHz, and the file size is around 2 MB after 10 minutes of recording.
+   * 1: Medium quality. The sample rate is 32 kHz, and the file size is around 2 MB after 10 minutes
+   * of recording.
    */
   AUDIO_RECORDING_QUALITY_MEDIUM = 1,
   /**
-   * 2: High quality. The sample rate is 32 kHz, and the file size is around 3.75 MB after 10 minutes of recording.
+   * 2: High quality. The sample rate is 32 kHz, and the file size is around 3.75 MB after 10
+   * minutes of recording.
    */
   AUDIO_RECORDING_QUALITY_HIGH = 2,
   /**
@@ -5352,7 +5750,8 @@
  */
 struct AudioRecordingConfiguration {
   /**
-   * The absolute path (including the filename extensions) of the recording file. For example: `C:\music\audio.mp4`.
+   * The absolute path (including the filename extensions) of the recording file. For example:
+   * `C:\music\audio.mp4`.
    * @note Ensure that the directory for the log files exists and is writable.
    */
   const char* filePath;
@@ -5368,8 +5767,9 @@
    * - (Default) 32000
    * - 44100
    * - 48000
-   * @note If you set this parameter to 44100 or 48000, Agora recommends recording WAV files, or AAC files with quality
-   * to be `AUDIO_RECORDING_QUALITY_MEDIUM` or `AUDIO_RECORDING_QUALITY_HIGH` for better recording quality.
+   * @note If you set this parameter to 44100 or 48000, Agora recommends recording WAV files, or AAC
+   * files with quality to be `AUDIO_RECORDING_QUALITY_MEDIUM` or `AUDIO_RECORDING_QUALITY_HIGH` for
+   * better recording quality.
    */
   int sampleRate;
   /**
@@ -5397,7 +5797,8 @@
       quality(AUDIO_RECORDING_QUALITY_LOW),
       recordingChannel(1) {}
 
-  AudioRecordingConfiguration(const char* file_path, int sample_rate, AUDIO_RECORDING_QUALITY_TYPE quality_type, int channel)
+  AudioRecordingConfiguration(const char* file_path, int sample_rate,
+                              AUDIO_RECORDING_QUALITY_TYPE quality_type, int channel)
       : filePath(file_path),
         encode(false),
         sampleRate(sample_rate),
@@ -5405,7 +5806,9 @@
       quality(quality_type),
       recordingChannel(channel) {}
 
-  AudioRecordingConfiguration(const char* file_path, bool enc, int sample_rate, AUDIO_FILE_RECORDING_TYPE type, AUDIO_RECORDING_QUALITY_TYPE quality_type, int channel)
+  AudioRecordingConfiguration(const char* file_path, bool enc, int sample_rate,
+                              AUDIO_FILE_RECORDING_TYPE type,
+                              AUDIO_RECORDING_QUALITY_TYPE quality_type, int channel)
       : filePath(file_path),
         encode(enc),
         sampleRate(sample_rate),
@@ -5413,7 +5816,7 @@
       quality(quality_type),
       recordingChannel(channel) {}
 
-  AudioRecordingConfiguration(const AudioRecordingConfiguration &rhs)
+  AudioRecordingConfiguration(const AudioRecordingConfiguration& rhs)
       : filePath(rhs.filePath),
         encode(rhs.encode),
         sampleRate(rhs.sampleRate),
@@ -5437,51 +5840,59 @@
 
     AudioEncodedFrameObserverConfig()
     : postionType(AUDIO_ENCODED_FRAME_OBSERVER_POSITION_PLAYBACK),
-      encodingType(AUDIO_ENCODING_TYPE_OPUS_48000_MEDIUM){}
-
+        encodingType(AUDIO_ENCODING_TYPE_OPUS_48000_MEDIUM) {}
 };
 /**
  * The encoded audio observer.
  */
 class IAudioEncodedFrameObserver {
-public:
-/**
-* Gets the encoded audio data of the local user.
-*
-* After calling `registerAudioEncodedFrameObserver` and setting the encoded audio as `AUDIO_ENCODED_FRAME_OBSERVER_POSITION_RECORD`,
-* you can get the encoded audio data of the local user from this callback.
-*
-* @param frameBuffer The pointer to the audio frame buffer.
-* @param length The data length (byte) of the audio frame.
-* @param audioEncodedFrameInfo Audio information after encoding. For details, see `EncodedAudioFrameInfo`.
-*/
-virtual void onRecordAudioEncodedFrame(const uint8_t* frameBuffer,  int length, const EncodedAudioFrameInfo& audioEncodedFrameInfo) = 0;
+ public:
+  /**
+   * Gets the encoded audio data of the local user.
+   *
+   * After calling `registerAudioEncodedFrameObserver` and setting the encoded audio as
+   * `AUDIO_ENCODED_FRAME_OBSERVER_POSITION_RECORD`, you can get the encoded audio data of the local
+   * user from this callback.
+   *
+   * @param frameBuffer The pointer to the audio frame buffer.
+   * @param length The data length (byte) of the audio frame.
+   * @param audioEncodedFrameInfo Audio information after encoding. For details, see
+   * `EncodedAudioFrameInfo`.
+   */
+  virtual void onRecordAudioEncodedFrame(const uint8_t* frameBuffer, int length,
+                                         const EncodedAudioFrameInfo& audioEncodedFrameInfo) = 0;
 
-/**
-* Gets the encoded audio data of all remote users.
-*
-* After calling `registerAudioEncodedFrameObserver` and setting the encoded audio as `AUDIO_ENCODED_FRAME_OBSERVER_POSITION_PLAYBACK`,
-* you can get encoded audio data of all remote users through this callback.
-*
-* @param frameBuffer The pointer to the audio frame buffer.
-* @param length The data length (byte) of the audio frame.
-* @param audioEncodedFrameInfo Audio information after encoding. For details, see `EncodedAudioFrameInfo`.
-*/
-virtual void onPlaybackAudioEncodedFrame(const uint8_t* frameBuffer,  int length, const EncodedAudioFrameInfo& audioEncodedFrameInfo) = 0;
+  /**
+   * Gets the encoded audio data of all remote users.
+   *
+   * After calling `registerAudioEncodedFrameObserver` and setting the encoded audio as
+   * `AUDIO_ENCODED_FRAME_OBSERVER_POSITION_PLAYBACK`, you can get encoded audio data of all remote
+   * users through this callback.
+   *
+   * @param frameBuffer The pointer to the audio frame buffer.
+   * @param length The data length (byte) of the audio frame.
+   * @param audioEncodedFrameInfo Audio information after encoding. For details, see
+   * `EncodedAudioFrameInfo`.
+   */
+  virtual void onPlaybackAudioEncodedFrame(const uint8_t* frameBuffer, int length,
+                                           const EncodedAudioFrameInfo& audioEncodedFrameInfo) = 0;
 
-/**
-* Gets the mixed and encoded audio data of the local and all remote users.
-*
-* After calling `registerAudioEncodedFrameObserver` and setting the audio profile as `AUDIO_ENCODED_FRAME_OBSERVER_POSITION_MIXED`,
-* you can get the mixed and encoded audio data of the local and all remote users through this callback.
-*
-* @param frameBuffer The pointer to the audio frame buffer.
-* @param length The data length (byte) of the audio frame.
-* @param audioEncodedFrameInfo Audio information after encoding. For details, see `EncodedAudioFrameInfo`.
-*/
-virtual void onMixedAudioEncodedFrame(const uint8_t* frameBuffer,  int length, const EncodedAudioFrameInfo& audioEncodedFrameInfo) = 0;
+  /**
+   * Gets the mixed and encoded audio data of the local and all remote users.
+   *
+   * After calling `registerAudioEncodedFrameObserver` and setting the audio profile as
+   * `AUDIO_ENCODED_FRAME_OBSERVER_POSITION_MIXED`, you can get the mixed and encoded audio data of
+   * the local and all remote users through this callback.
+   *
+   * @param frameBuffer The pointer to the audio frame buffer.
+   * @param length The data length (byte) of the audio frame.
+   * @param audioEncodedFrameInfo Audio information after encoding. For details, see
+   * `EncodedAudioFrameInfo`.
+   */
+  virtual void onMixedAudioEncodedFrame(const uint8_t* frameBuffer, int length,
+                                        const EncodedAudioFrameInfo& audioEncodedFrameInfo) = 0;
 
-virtual ~IAudioEncodedFrameObserver () {}
+  virtual ~IAudioEncodedFrameObserver() {}
 };
 
 /** The region for connection, which is the region where the server the SDK connects to is located.
@@ -5568,8 +5979,9 @@
   RELAY_ERROR_SERVER_ERROR_RESPONSE = 1,
   /** 2: No server response. You can call the `leaveChannel` method to leave the channel.
    *
-   * This error can also occur if your project has not enabled co-host token authentication. You can contact technical
-   * support to enable the service for cohosting across channels before starting a channel media relay.
+   * This error can also occur if your project has not enabled co-host token authentication. You can
+   * contact technical support to enable the service for cohosting across channels before starting a
+   * channel media relay.
    */
   RELAY_ERROR_SERVER_NO_RESPONSE = 2,
   /** 3: The SDK fails to access the service, probably due to limited resources of the server.
@@ -5587,8 +5999,8 @@
   /** 7: The server fails to send the media stream.
    */
   RELAY_ERROR_FAILED_PACKET_SENT_TO_DEST = 7,
-  /** 8: The SDK disconnects from the server due to poor network connections. You can call the `leaveChannel` method to
-   * leave the channel.
+  /** 8: The SDK disconnects from the server due to poor network connections. You can call the
+   * `leaveChannel` method to leave the channel.
    */
   RELAY_ERROR_SERVER_CONNECTION_LOST = 8,
   /** 9: An internal error occurs in the server.
@@ -5606,8 +6018,8 @@
  * The state code of the channel media relay.
  */
 enum CHANNEL_MEDIA_RELAY_STATE {
-  /** 0: The initial state. After you successfully stop the channel media relay by calling `stopChannelMediaRelay`,
-   * the `onChannelMediaRelayStateChanged` callback returns this state.
+  /** 0: The initial state. After you successfully stop the channel media relay by calling
+   * `stopChannelMediaRelay`, the `onChannelMediaRelayStateChanged` callback returns this state.
    */
   RELAY_STATE_IDLE = 0,
   /** 1: The SDK tries to relay the media stream to the destination channel.
@@ -5644,31 +6056,32 @@
  */
 struct ChannelMediaRelayConfiguration {
   /** The information of the source channel `ChannelMediaInfo`. It contains the following members:
-   * - `channelName`: The name of the source channel. The default value is `NULL`, which means the SDK applies the name
-   * of the current channel.
-   * - `uid`: The unique ID to identify the relay stream in the source channel. The default value is 0, which means the
-   * SDK generates a random UID. You must set it as 0.
-   * - `token`: The token for joining the source channel. It is generated with the `channelName` and `uid` you set in
-   * `srcInfo`.
-   *   - If you have not enabled the App Certificate, set this parameter as the default value `NULL`, which means the
-   * SDK applies the App ID.
-   *   - If you have enabled the App Certificate, you must use the token generated with the `channelName` and `uid`, and
-   * the `uid` must be set as 0.
+   * - `channelName`: The name of the source channel. The default value is `NULL`, which means the
+   * SDK applies the name of the current channel.
+   * - `uid`: The unique ID to identify the relay stream in the source channel. The default value is
+   * 0, which means the SDK generates a random UID. You must set it as 0.
+   * - `token`: The token for joining the source channel. It is generated with the `channelName` and
+   * `uid` you set in `srcInfo`.
+   *   - If you have not enabled the App Certificate, set this parameter as the default value
+   * `NULL`, which means the SDK applies the App ID.
+   *   - If you have enabled the App Certificate, you must use the token generated with the
+   * `channelName` and `uid`, and the `uid` must be set as 0.
    */
   ChannelMediaInfo* srcInfo;
-  /** The information of the destination channel `ChannelMediaInfo`. It contains the following members:
+  /** The information of the destination channel `ChannelMediaInfo`. It contains the following
+   * members:
    * - `channelName`: The name of the destination channel.
    * - `uid`: The unique ID to identify the relay stream in the destination channel. The value
    * ranges from 0 to (2^32-1). To avoid UID conflicts, this `UID` must be different from any
    * other `UID` in the destination channel. The default value is 0, which means the SDK generates
    * a random `UID`. Do not set this parameter as the `UID` of the host in the destination channel,
    * and ensure that this `UID` is different from any other `UID` in the channel.
-   * - `token`: The token for joining the destination channel. It is generated with the `channelName`
-   * and `uid` you set in `destInfos`.
+   * - `token`: The token for joining the destination channel. It is generated with the
+   * `channelName` and `uid` you set in `destInfos`.
    *   - If you have not enabled the App Certificate, set this parameter as the default value NULL,
    * which means the SDK applies the App ID.
-   * If you have enabled the App Certificate, you must use the token generated with the `channelName`
-   * and `uid`.
+   * If you have enabled the App Certificate, you must use the token generated with the
+   * `channelName` and `uid`.
    */
   ChannelMediaInfo* destInfos;
   /** The number of destination channels. The default value is 0, and the value range is from 0 to
@@ -5677,7 +6090,8 @@
    */
   int destCount;
 
-  ChannelMediaRelayConfiguration() : srcInfo(OPTIONAL_NULLPTR), destInfos(OPTIONAL_NULLPTR), destCount(0) {}
+  ChannelMediaRelayConfiguration()
+      : srcInfo(OPTIONAL_NULLPTR), destInfos(OPTIONAL_NULLPTR), destCount(0) {}
 };
 
 /**
@@ -5726,7 +6140,7 @@
           current_downscale_level(rhs.current_downscale_level),
           expected_bitrate_bps(rhs.expected_bitrate_bps) {
       if (rhs.userId != OPTIONAL_NULLPTR) {
-        const int len = std::strlen(rhs.userId);
+        const size_t len = std::strlen(rhs.userId);
         char* buf = new char[len + 1];
         std::memcpy(buf, rhs.userId, len);
         buf[len] = '\0';
@@ -5741,7 +6155,7 @@
       current_downscale_level = rhs.current_downscale_level;
       expected_bitrate_bps = rhs.expected_bitrate_bps;
       if (rhs.userId != OPTIONAL_NULLPTR) {
-        const int len = std::strlen(rhs.userId);
+        const size_t len = std::strlen(rhs.userId);
         char* buf = new char[len + 1];
         std::memcpy(buf, rhs.userId, len);
         buf[len] = '\0';
@@ -5840,7 +6254,8 @@
    * salt (`encryptionKdfSalt`).
    */
   AES_128_GCM2 = 7,
-  /** 8: 256-bit AES encryption, GCM mode. This encryption mode requires the setting of salt (`encryptionKdfSalt`).
+  /** 8: 256-bit AES encryption, GCM mode. This encryption mode requires the setting of salt
+   * (`encryptionKdfSalt`).
    */
   AES_256_GCM2 = 8,
   /** Enumerator boundary.
@@ -5858,11 +6273,13 @@
   /**
    * Encryption key in string type with unlimited length. Agora recommends using a 32-byte key.
    *
-   * @note If you do not set an encryption key or set it as NULL, you cannot use the built-in encryption, and the SDK returns #ERR_INVALID_ARGUMENT (-2).
+   * @note If you do not set an encryption key or set it as NULL, you cannot use the built-in
+   * encryption, and the SDK returns #ERR_INVALID_ARGUMENT (-2).
    */
   const char* encryptionKey;
   /**
-   * Salt, 32 bytes in length. Agora recommends that you use OpenSSL to generate salt on the server side.
+   * Salt, 32 bytes in length. Agora recommends that you use OpenSSL to generate salt on the server
+   * side.
    *
    * @note This parameter takes effect only in `AES_128_GCM2` or `AES_256_GCM2` encrypted mode.
    * In this case, ensure that this parameter is not 0.
@@ -5874,14 +6291,13 @@
   EncryptionConfig()
     : encryptionMode(AES_128_GCM2),
       encryptionKey(OPTIONAL_NULLPTR),
-      datastreamEncryptionEnabled(false)
-  {
+        datastreamEncryptionEnabled(false) {
     memset(encryptionKdfSalt, 0, sizeof(encryptionKdfSalt));
   }
 
   /// @cond
   const char* getEncryptionString() const {
-    switch(encryptionMode) {
+    switch (encryptionMode) {
       case AES_128_XTS:
         return "aes-128-xts";
       case AES_128_ECB:
@@ -5914,7 +6330,8 @@
      */
     ENCRYPTION_ERROR_INTERNAL_FAILURE = 0,
     /**
-     * 1: MediaStream decryption errors. Ensure that the receiver and the sender use the same encryption mode and key.
+   * 1: MediaStream decryption errors. Ensure that the receiver and the sender use the same
+   * encryption mode and key.
    */
   ENCRYPTION_ERROR_DECRYPTION_FAILURE = 1,
   /**
@@ -5922,7 +6339,8 @@
      */
     ENCRYPTION_ERROR_ENCRYPTION_FAILURE = 2,
     /**
-     * 3: DataStream decryption errors. Ensure that the receiver and the sender use the same encryption mode and key.
+   * 3: DataStream decryption errors. Ensure that the receiver and the sender use the same
+   * encryption mode and key.
    */
   ENCRYPTION_ERROR_DATASTREAM_DECRYPTION_FAILURE = 3,
   /**
@@ -5931,8 +6349,7 @@
     ENCRYPTION_ERROR_DATASTREAM_ENCRYPTION_FAILURE = 4,
 };
 
-enum UPLOAD_ERROR_REASON
-{
+enum UPLOAD_ERROR_REASON {
   UPLOAD_SUCCESS = 0,
   UPLOAD_NET_ERROR = 1,
   UPLOAD_SERVER_ERROR = 2,
@@ -5967,7 +6384,8 @@
    *   - Calls `muteLocalAudioStream(true)` or `muteLocalVideoStream(true)` to stop sending local
    * media stream.
    *   - Calls `disableAudio` or `disableVideo `to disable the local audio or video module.
-   *   - Calls `enableLocalAudio(false)` or `enableLocalVideo(false)` to disable the local audio or video capture.
+   *   - Calls `enableLocalAudio(false)` or `enableLocalVideo(false)` to disable the local audio or
+   * video capture.
    *   - The role of the remote user is audience.
    * - The local user calls the following methods to stop receiving remote streams:
    *   - Calls `muteRemoteAudioStream(true)`, `muteAllRemoteAudioStreams(true)` to stop receiving the remote audio streams.
@@ -5994,9 +6412,12 @@
   PUB_STATE_IDLE = 0,
   /**
    * 1: Fails to publish the local stream. Possible reasons:
-   * - The local user calls `muteLocalAudioStream(true)` or `muteLocalVideoStream(true)` to stop sending the local media stream.
-   * - The local user calls `disableAudio` or `disableVideo` to disable the local audio or video module.
-   * - The local user calls `enableLocalAudio(false)` or `enableLocalVideo(false)` to disable the local audio or video capture.
+   * - The local user calls `muteLocalAudioStream(true)` or `muteLocalVideoStream(true)` to stop
+   * sending the local media stream.
+   * - The local user calls `disableAudio` or `disableVideo` to disable the local audio or video
+   * module.
+   * - The local user calls `enableLocalAudio(false)` or `enableLocalVideo(false)` to disable the
+   * local audio or video capture.
    * - The role of the local user is audience.
    */
   PUB_STATE_NO_PUBLISHED = 1,
@@ -6025,7 +6446,12 @@
    : view(v), enableAudio(ea), enableVideo(ev), token(t), channelId(c), intervalInSeconds(is) {}
 
   EchoTestConfiguration()
-   : view(OPTIONAL_NULLPTR), enableAudio(true), enableVideo(true), token(OPTIONAL_NULLPTR), channelId(OPTIONAL_NULLPTR), intervalInSeconds(2) {}
+      : view(OPTIONAL_NULLPTR),
+        enableAudio(true),
+        enableVideo(true),
+        token(OPTIONAL_NULLPTR),
+        channelId(OPTIONAL_NULLPTR),
+        intervalInSeconds(2) {}
 };
 
 /**
@@ -6041,9 +6467,7 @@
    */
   char userAccount[MAX_USER_ACCOUNT_LENGTH];
 
-  UserInfo() : uid(0) {
-    userAccount[0] = '\0';
-  }
+  UserInfo() : uid(0) { userAccount[0] = '\0'; }
 };
 
 /**
@@ -6053,21 +6477,22 @@
   /**
    * 1: Do not add an audio filter to the in-ear monitor.
    */
-  EAR_MONITORING_FILTER_NONE = (1<<0),
+  EAR_MONITORING_FILTER_NONE = (1 << 0),
   /**
    * 2: Enable audio filters to the in-ear monitor. If you implement functions such as voice
    * beautifier and audio effect, users can hear the voice after adding these effects.
    */
-  EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS = (1<<1),
+  EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS = (1 << 1),
   /**
    * 4: Enable noise suppression to the in-ear monitor.
    */
-  EAR_MONITORING_FILTER_NOISE_SUPPRESSION = (1<<2),
+  EAR_MONITORING_FILTER_NOISE_SUPPRESSION = (1 << 2),
   /**
    * 32768: Enable audio filters by reuse post-processing filter to the in-ear monitor.
-   * This bit is intended to be used in exclusive mode, which means, if this bit is set, all other bits will be disregarded.
+   * This bit is intended to be used in exclusive mode, which means, if this bit is set, all other
+   * bits will be disregarded.
    */
-  EAR_MONITORING_FILTER_REUSE_POST_PROCESSING_FILTER = (1<<15),
+  EAR_MONITORING_FILTER_REUSE_POST_PROCESSING_FILTER = (1 << 15),
 };
 
 /**
@@ -6286,7 +6711,6 @@
   CONFIG_FETCH_TYPE_JOIN_CHANNEL = 2,
 };
 
-
 /** The local  proxy mode type. */
 enum LOCAL_PROXY_MODE {
   /** 0: Connect local proxy with high priority, if not connected to local proxy, fallback to sdrtn.
@@ -6315,7 +6739,8 @@
 
   LogUploadServerInfo() : serverDomain(NULL), serverPath(NULL), serverPort(0), serverHttps(true) {}
 
-  LogUploadServerInfo(const char* domain, const char* path, int port, bool https) : serverDomain(domain), serverPath(path), serverPort(port), serverHttps(https) {}
+  LogUploadServerInfo(const char* domain, const char* path, int port, bool https)
+      : serverDomain(domain), serverPath(path), serverPort(port), serverHttps(https) {}
 };
 
 struct AdvancedConfigInfo {
@@ -6337,8 +6762,9 @@
   /** The number of local access point domain.
    */
   int domainListSize;
-  /** Certificate domain name installed on specific local access point. pass "" means using sni domain on specific local access point
-   *  SNI(Server Name Indication) is an extension to the TLS protocol.
+  /** Certificate domain name installed on specific local access point. pass "" means using sni
+   * domain on specific local access point SNI(Server Name Indication) is an extension to the TLS
+   * protocol.
    */
   const char* verifyDomainName;
   /** Local proxy connection mode, connectivity first or local only.
@@ -6353,23 +6779,42 @@
     - false: not disable vos-aut
   */
   bool disableAut;
-  LocalAccessPointConfiguration() : ipList(NULL), ipListSize(0), domainList(NULL), domainListSize(0), verifyDomainName(NULL), mode(ConnectivityFirst), disableAut(true) {}
+  LocalAccessPointConfiguration()
+      : ipList(NULL),
+        ipListSize(0),
+        domainList(NULL),
+        domainListSize(0),
+        verifyDomainName(NULL),
+        mode(ConnectivityFirst),
+        disableAut(true) {}
 };
 
+enum RecorderStreamType {
+  RTC,
+  PREVIEW,
+};
+
 /**
  * The information about recorded media streams.
  */
 struct RecorderStreamInfo {
+  /**
+   * The channel ID of the audio/video stream needs to be recorded.
+   */
     const char* channelId;
     /**
      * The user ID.
      */
     uid_t uid;
     /**
-     * The channel ID of the audio/video stream needs to be recorded.
+   * The Recoder Stream type.
      */
-    RecorderStreamInfo() : channelId(NULL), uid(0) {}
-    RecorderStreamInfo(const char* channelId, uid_t uid) : channelId(channelId), uid(uid) {}
+  RecorderStreamType type;
+  RecorderStreamInfo() : channelId(NULL), uid(0), type(RTC) {}
+  RecorderStreamInfo(const char* channelId, uid_t uid)
+      : channelId(channelId), uid(uid), type(RTC) {}
+  RecorderStreamInfo(const char* channelId, uid_t uid, RecorderStreamType type)
+      : channelId(channelId), uid(uid), type(type) {}
 };
 }  // namespace rtc
 
@@ -6445,9 +6890,8 @@
 };
 /**
  * Layout info of video stream which compose a transcoder video stream.
-*/
-struct VideoLayout
-{
+ */
+struct VideoLayout {
   /**
    * Channel Id from which this video stream come from.
    */
@@ -6482,7 +6926,15 @@
   */ 
   uint32_t videoState; 
 
-  VideoLayout() : channelId(OPTIONAL_NULLPTR), uid(0), strUid(OPTIONAL_NULLPTR), x(0), y(0), width(0), height(0), videoState(0) {}
+  VideoLayout()
+      : channelId(OPTIONAL_NULLPTR),
+        uid(0),
+        strUid(OPTIONAL_NULLPTR),
+        x(0),
+        y(0),
+        width(0),
+        height(0),
+        videoState(0) {}
 };
 }  // namespace agora
 
@@ -6509,7 +6961,7 @@
  * @note For license only, everytime will generate a different credential.
  * So, just need to call once for a device, and then save the credential
  */
-AGORA_API int AGORA_CALL createAgoraCredential(agora::util::AString &credential);
+AGORA_API int AGORA_CALL createAgoraCredential(agora::util::AString& credential);
 
 /**
  * Verify given certificate and return the result
@@ -6524,8 +6976,10 @@
  * @return The description of the error code.
  * @note For license only.
  */
-AGORA_API int AGORA_CALL getAgoraCertificateVerifyResult(const char *credential_buf, int credential_len,
-    const char *certificate_buf, int certificate_len);
+AGORA_API int AGORA_CALL getAgoraCertificateVerifyResult(const char* credential_buf,
+                                                         int credential_len,
+                                                         const char* certificate_buf,
+                                                         int certificate_len);
 
 /**
  * @brief Implement the agora::base::LicenseCallback,
@@ -6534,7 +6988,7 @@
  * @param [in] callback The object of agora::LiceseCallback,
  *                      set the callback to null before delete it.
  */
-AGORA_API void setAgoraLicenseCallback(agora::base::LicenseCallback *callback);
+AGORA_API void setAgoraLicenseCallback(agora::base::LicenseCallback* callback);
 
 /**
  * @brief Get the LicenseCallback pointer if already setup,
@@ -6550,17 +7004,14 @@
  * typical scenario is as follows:
  *
  *  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
- *  |  // custom audio/video base capture time, e.g. the first audio/video capture time.             |
- *  |  int64_t custom_capture_time_base;                                                             |
- *  |                                                                                                |
- *  |  int64_t agora_monotonic_time = getAgoraCurrentMonotonicTimeInMs();                            |
- *  |                                                                                                |
- *  |  // offset is fixed once calculated in the begining.                                           |
- *  |  const int64_t offset = agora_monotonic_time - custom_capture_time_base;                       |
- *  |                                                                                                |
- *  |  // realtime_custom_audio/video_capture_time is the origin capture time that customer provided.|
- *  |  // actual_audio/video_capture_time is the actual capture time transfered to sdk.              |
- *  |  int64_t actual_audio_capture_time = realtime_custom_audio_capture_time + offset;              |
+ *  |  // custom audio/video base capture time, e.g. the first audio/video capture time. | | int64_t
+ * custom_capture_time_base;                                                             | | | |
+ * int64_t agora_monotonic_time = getAgoraCurrentMonotonicTimeInMs();                            |
+ *  | | |  // offset is fixed once calculated in the begining. | |  const int64_t offset =
+ * agora_monotonic_time - custom_capture_time_base;                       | | | |  //
+ * realtime_custom_audio/video_capture_time is the origin capture time that customer provided.| | //
+ * actual_audio/video_capture_time is the actual capture time transfered to sdk.              | |
+ * int64_t actual_audio_capture_time = realtime_custom_audio_capture_time + offset;              |
  *  |  int64_t actual_video_capture_time = realtime_custom_video_capture_time + offset; |
  *  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
  *
diff -u -b -r headers/rtc_4.4.0/include/AgoraMediaBase.h headers/rtc_4.5.0/include/AgoraMediaBase.h